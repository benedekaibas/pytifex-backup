{
  "method": "all",
  "evaluations": [
    {
      "filename": "generic-typevar-bound-specialization.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/generic-typevar-bound-specialization.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "PARTIAL",
            "reason": "Mypy correctly found no issues in the active code, but it missed the one potential type issue identified in the analysis because that line was commented out in the provided code, which type checkers typically ignore.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Instantiation of a generic type parameterized by a TypeVar outside of a generic context.\n  - Line: 41 (commented out)\n  - Rule: A generic type parameterized by a bare TypeVar cannot be directly instantiated or assigned to, as it represents a generic type rather than a concrete instance. Instances must have concrete types substituted for their TypeVars.\n  - PEP Reference: PEP 484, \"The `TypeVar` class\"\n  - Should Error: YES\n\n**Explanation for Issue 1:**\nThe commented-out line `class_level_box: Box[T_IntList] = Box(my_data)` attempts to assign an instance of `Box[List[int]]` (inferred from `Box(my_data)`) to a variable annotated as `Box[T_IntList]`. `T_IntList` is a global `TypeVar`. Outside of a generic function or class definition, `Box[T_IntList]` refers to the generic type itself, not a concrete type. According to PEP 484, it is an error to instantiate or assign to a generic type directly in this manner. For example, `x = MyClass[T]()` is explicitly stated as an error. The variable `class_level_box` needs a concrete type (like `Box[List[int]]`) not a generic placeholder `Box[T_IntList]` if it's meant to hold a concrete instance.\n\n**Analysis of other potentially confusing parts (not type safety violations):**\n\n*   **`ConfusingBoxType = Box[T_IntList]` (Line 21):** This is a valid generic type alias definition. `ConfusingBoxType` becomes a generic alias parameterized implicitly by `T_IntList`. `T_IntList` (the `TypeVar`) is a valid type argument because it is a subtype of its own bound (`List[int]`).\n\n*   **`box_instance: ConfusingBoxType[T_IntList]` (Line 23):** This is a valid type hint. When `T_IntList` appears in a function signature, it makes the function `check_box` generic over `T_IntList`. `ConfusingBoxType[T_IntList]` means specializing the generic alias `ConfusingBoxType` (which itself is `Box[T_IntList]`) with the `TypeVar T_IntList`. This resolves to `Box[T_IntList]`, where `T_IntList` is the TypeVar of the generic function `check_box`. While somewhat redundant (using `ConfusingBoxType` alone would often imply the same generic context), it is not a type safety violation.\n\n*   **`reveal_type(box_instance.item)` (Line 28):** `box_instance` has type `Box[T_IntList]` (from the function's generic parameter). Therefore, `box_instance.item` correctly has type `T_IntList`. This allows access to `box_instance.item[0]` because `T_IntList` is bound to `List[int]`.\n\n*   **`result = check_box(concrete_box)` (Line 37):** `concrete_box` has type `Box[List[int]]`. The `check_box` function is generic over `T_IntList` and expects an argument of type `Box[T_IntList]`. `List[int]` is a valid substitute for `T_IntList` (as it satisfies the bound `List[int]`). Type checkers will successfully infer `T_IntList` as `List[int]` for this call, making the call type-safe.\n\nThe code, *excluding the commented-out line*, is type-safe according to the provided PEPs.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code would fail at runtime. ",
            "has_runtime_error": true,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker reported 0 errors, completely missing both type safety issues identified in the analysis.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "Here's an analysis of the provided code for type safety issues, ignoring all comments in the source code as requested.\n\nISSUE 1: Invalid Parameterization of a Type Alias\n  - Line: 24\n  - Rule: A type alias defined without explicit generic parameters (e.g., `Alias = OriginalType[SpecificTypeArg]`) becomes a specific, non-generic type. It cannot subsequently be parameterized with type arguments (e.g., `Alias[AnotherTypeArg]`) as if it were a generic alias itself.\n  - PEP Reference: PEP 484, Section \"Type aliases\". While not explicitly forbidden by a specific sentence, this usage violates the fundamental understanding of how type aliases and generic type parameterization work. `ConfusingBoxType = Box[T_IntList]` makes `ConfusingBoxType` equivalent to `Box[T_IntList]`. Attempting `ConfusingBoxType[T_IntList]` is like trying to write `(Box[T_IntList])[T_IntList]`, which is syntactically and semantically incorrect; generic types are parameterized once. If `ConfusingBoxType` were intended to be a generic alias, it should have been defined as `ConfusingBoxType[U] = Box[U]` (or similar).\n  - Should Error: YES\n\nISSUE 2: Invalid Assignment of a Concrete Generic Type to a Generic Type with a Free TypeVar\n  - Line: 45 (commented out in the provided code, but type checkers should analyze commented-out code if run in a \"full file\" mode or if it were uncommented.)\n  - Rule: A concrete instantiation of a generic type (e.g., `Box[List[int]]`) cannot be assigned to a variable annotated with a generic type where its TypeVar is \"free\" (e.g., `Box[T_IntList]`). When `T_IntList` appears freely in an annotation like `Box[T_IntList]` for a variable, it implies that the variable could hold *any* `Box[X]` where `X` satisfies `T_IntList`'s bound. A concrete `Box[List[int]]` is not polymorphic over `T_IntList` and therefore cannot satisfy such an annotation. This would violate type safety by allowing a specific type to masquerade as a more general (polymorphic) type.\n  - PEP Reference: PEP 484, Section \"Type variables\" and \"Generic types\". A TypeVar needs to be bound by a generic context (like a function or class) or instantiated to a concrete type. Using `T_IntList` in `Box[T_IntList]` for a variable's annotation makes `T_IntList` free, implying a polymorphic variable, which `Box(my_data)` (yielding `Box[List[int]]`) cannot satisfy.\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker did not process the file due to an inability to find it, resulting in no type checking being performed and all issues being missed.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Attempt to parameterize a type alias that is already specialized.\n  - Line: 28 (`def check_box(box_instance: ConfusingBoxType[T_IntList]) -> int:`)\n  - Rule: A type alias defined as a specific specialization of a generic type (e.g., `Alias = GenericType[SpecificArg]`) cannot itself be further parameterized. This is because `ConfusingBoxType` is defined as `Box[T_IntList]`, making it an alias for an already specialized generic type. It is not a generic alias (which would be defined as `Alias[U] = GenericType[U]`). Attempting to subscript `ConfusingBoxType` with `[T_IntList]` is akin to `(Box[T_IntList])[T_IntList]`, which is syntactically invalid for a specialized type.\n  - PEP Reference: PEP 484, section \"Type aliases\" and \"The `Generic` type\". The rule is a fundamental aspect of how generic types and type aliases are structured and used in Python's type system.\n  - Should Error: YES. This is a clear and unambiguous structural error in the type annotation.\n\n*Consequence of Issue 1:*\nThe call `result = check_box(concrete_box)` on Line 42 would also typically be flagged as an error, because the argument `concrete_box` (of type `Box[List[int]]`) cannot be assigned to a parameter type that is itself invalid (`ConfusingBoxType[T_IntList]`). This is a cascading error rather than a separate, distinct issue.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code would fail at runtime. ",
            "has_runtime_error": true,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker did not report any of the identified critical type safety errors and only provided an informational output.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "Here's an analysis of the provided code for type safety issues:\n\nISSUE 1: Invalid type argument for a generic class specialization.\n  - Line: 21\n  - Rule: A `TypeVar` (like `T_IntList` defined at the module level) cannot be used directly as a concrete type argument to specialize a generic class (`Box`) if that `TypeVar` is not a `TypeVar` of an *outer* generic class or function. The `TypeVar` object itself does not satisfy the bound of `Box`'s type parameter (`List[int]`) because a `TypeVar` is a placeholder for types, not a concrete type that participates in subtyping relationships in this context. The expectation for a type argument is a type that is a subtype of the bound, not the `TypeVar` itself.\n  - PEP Reference: PEP 484, Sections \"Type variables\" and \"Generic types and abstract base classes.\" The rules for type variable substitution and bounds checking implicitly forbid a `TypeVar` from being its own concrete substitution argument in this manner.\n  - Should Error: YES. Modern type checkers (e.g., MyPy, Pyright) correctly flag this as an error.\n\nISSUE 2: Attempt to specialize a type alias that is already fully specialized (or ill-formed).\n  - Line: 23\n  - Rule: The alias `ConfusingBoxType` is defined on line 21 as `Box[T_IntList]`. This declaration, even if `Box[T_IntList]` itself is problematic (as per ISSUE 1), creates a specific (though ill-formed) type, not a generic alias that accepts further type parameters. Attempting to specialize `ConfusingBoxType` again with `[T_IntList]` (i.e., `ConfusingBoxType[T_IntList]`) is an incorrect application of generic syntax. A type that is already fully specialized (or a non-generic type) cannot be specialized further.\n  - PEP Reference: PEP 484, Sections \"Type aliases\" and \"Generic types and abstract base classes.\" This rule dictates that a type alias defined as `Alias = SpecificGeneric[ConcreteType]` results in `Alias` being a concrete type, not a generic one that can be parameterized again. To define a *generic alias*, it would need its own type variables, e.g., `GenericAlias[U] = SpecificGeneric[U]`.\n  - Should Error: YES. Type checkers consistently report an error here, often stating that the alias is \"not generic.\"",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code would fail at runtime. ",
            "has_runtime_error": true,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "self-in-abstract-generic-class-var.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/self-in-abstract-generic-class-var.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "INCORRECT",
            "reason": "Mypy reported \"Success: no issues found\" despite the code containing critical type safety violations stemming from the interaction of `typing.Self` with a mutable, shared class variable, which leads to runtime type corruption and potential `AttributeError`s.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "Here's an analysis of the provided code for type safety issues, strictly following Python typing rules and PEPs. The core challenge in this code revolves around the interaction of `typing.Self`, `typing.Generic`, and Python's object model for mutable class variables.\n\nAccording to PEP 673, when `Self` is used in a class attribute's type annotation, \"When accessed on a subclass, the attribute's type is specialized by the subclass type.\" This means `IntConfigurator._registered_instances` *should* be viewed by a type checker as `List[IntConfigurator]`, and `StrConfigurator._registered_instances` as `List[StrConfigurator]`.\n\nHowever, the initialization `_registered_instances: List[Self] = []` creates a *single mutable list object* in Python's object model. This list object is then inherited and *shared* by all subclasses. This discrepancy between the static type view (specialized by `Self`) and the runtime object identity (a single shared list) leads to significant type safety violations.\n\nHere are the potential type safety violations:\n\nISSUE 1: Type Inconsistency due to Shared Mutable Class Variable\n  - Line: 10 (`_registered_instances: List[Self] = []`)\n  - Rule: Violation of type consistency for a shared mutable class variable. The initialization `_registered_instances: List[Self] = []` creates a single list object that is inherited and shared by all concrete subclasses (e.g., `IntConfigurator` and `StrConfigurator`). While PEP 673 dictates that the *type view* of `_registered_instances` when accessed via a subclass should be specialized (e.g., `IntConfigurator._registered_instances` is `List[IntConfigurator]`), the underlying Python object model means all concrete subclasses append their instances to the *same physical list*. This leads to runtime type corruption where the list, statically viewed as containing only `IntConfigurator`s, can actually contain `StrConfigurator`s (and vice-versa). The static type information becomes unreliable at runtime.\n  - PEP Reference: PEP 484 (type compatibility, list covariance). While PEP 673 governs `Self`'s interpretation, this issue arises from the interaction between Python's class variable mechanics and the type system's assumptions, leading to a violation of type safety.\n  - Should Error: YES. A robust type checker should issue a warning about mutable class variables initialized this way with `Self`, as it creates a high risk of runtime type mismatches. Some checkers might flag this as inconsistent types across program or incompatible type assignment.\n\nISSUE 2: Potential `AttributeError` due to Runtime Type Mismatch\n  - Line: 47 (`print(f\"First int config specific value: {first_int_config.get_specific_int_value()}\")`)\n  - Rule: Accessing an attribute/method that does not exist on the runtime object's type, despite static type inference. Due to the shared mutable list issue (ISSUE 1), `IntConfigurator._registered_instances[0]` could at runtime retrieve an object of a type other than `IntConfigurator` (e.g., a `StrConfigurator`). If a `StrConfigurator` object is retrieved, attempting to call `get_specific_int_value()` on it will raise an `AttributeError` because `StrConfigurator` does not have this method. This is a direct runtime consequence of the type corruption described in ISSUE 1.\n  - PEP Reference: PEP 484 (basic type checking for attribute access and method existence). This is a critical runtime failure stemming from an underlying static type assumption being violated.\n  - Should Error: YES. This line is highly vulnerable to runtime errors because its static type relies on the problematic `Self` interpretation over a shared mutable state.\n\nISSUE 3: Violation of List Covariance (if uncommented)\n  - Line: 55 (commented: `IntConfigurator._registered_instances.append(s1)`)\n  - Rule: Incompatible type for list append. If this line were uncommented, `IntConfigurator._registered_instances` is correctly inferred (per PEP 673) as `List[IntConfigurator]`. Attempting to append `s1` (an instance of `StrConfigurator`) to a list expecting `IntConfigurator` objects is a type safety violation because `StrConfigurator` is not a subtype of `IntConfigurator`. This line serves as a clear example of a type error that *should* be caught, demonstrating the correct behavior if `Self` specializes as intended and the lists were not shared.\n  - PEP Reference: PEP 484 (Generics, specifically list covariance and type compatibility rules).\n  - Should Error: YES. If this line were uncommented, a type checker *must* report a type error.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker incorrectly flagged a type-safe operation on line 14 as an error, indicating a failure to correctly implement PEP 673's `Self` for class variable access via `type(self)`, while otherwise correctly interpreting `Self` for direct subclass access (lines 54, 55).",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "ISSUE 1: **Attempt to append an instance of a different subclass to a subclass-specific registry list.**\n  - Line: 53 (commented out line: `IntConfigurator._registered_instances.append(s1)`)\n  - Rule: Type incompatibility in list append operation. According to PEP 673, `IntConfigurator._registered_instances` should be typed as `List[IntConfigurator]`. Appending `s1`, which is an instance of `StrConfigurator`, to this list is a type violation because `StrConfigurator` is not a subtype of `IntConfigurator`. `List` is covariant in its type parameter, meaning elements appended must be compatible with the list's element type.\n  - PEP Reference: PEP 484, \"Subtyping and Variance\", general type compatibility rules; PEP 673, \"Class variables and Self\" (for the correct interpretation of `_registered_instances` type).\n  - Should Error: YES. If this line were uncommented, a type checker compliant with PEP 673 would correctly identify this as a type error.\n\n**Analysis of other \"DISAGREEMENT POINTS\" and `reveal_type` calls:**\n\n1.  **`_registered_instances: List[Self] = []` (Line 10)**: This is a type-safe declaration. The `Self` type, as defined in PEP 673, when used in a class variable annotation, refers to the specific subclass accessing the variable. The initial empty list `[]` is compatible with `List[Self]` (as `List[Never]` or `List[Any]` can be assigned).\n\n2.  **`type(self)._registered_instances.append(self)` (Line 14)**: This operation is type-safe. When `self` is an `IntConfigurator`, `type(self)` resolves to `IntConfigurator`, and `IntConfigurator._registered_instances` is `List[IntConfigurator]`. Appending `self` (an `IntConfigurator`) to this list is correct. The same logic applies to `StrConfigurator`.\n\n3.  **`reveal_type(IntConfigurator._registered_instances)` (Line 42)**: According to PEP 673 (\"Class variables and Self\" section), when `Self` is used in a class variable and accessed via a subclass, it refers to that subclass. Therefore, a compliant type checker *should* infer the type as `List[IntConfigurator]`. The code itself is correct by spec here; any disagreement would stem from a type checker's incomplete implementation of PEP 673.\n\n4.  **`reveal_type(StrConfigurator._registered_instances)` (Line 43)**: Similarly, this *should* be inferred as `List[StrConfigurator]` by a compliant type checker based on PEP 673.\n\n5.  **`print(f\"First int config specific value: {first_int_config.get_specific_int_value()}\")` (Line 47)**: If `IntConfigurator._registered_instances` is correctly inferred as `List[IntConfigurator]` (as per PEP 673), then `first_int_config` will be inferred as `IntConfigurator`. Calling `get_specific_int_value()` on an `IntConfigurator` object is type-safe and valid, as this method is defined on `IntConfigurator`. The code is type-safe here according to PEPs. If a type checker fails to correctly infer `Self`, it might incorrectly type `first_int_config` as `BaseConfigurator[int]`, which would then lead to an attribute access error for `get_specific_int_value()`. However, this would be a type checker implementation defect, not a violation within the code against the PEPs.\n\n**Conclusion:**\nBased on a strict interpretation of Python typing rules and PEPs (especially PEP 673 for `Self`), the provided code is type-safe, **assuming line 53 remains commented out**. The only explicit type safety violation demonstrated in the code occurs if line 53 were to be uncommented. The \"disagreement points\" in the original comments refer to common challenges or inconsistencies in how various type checkers implement certain advanced features like `Self`, rather than inherent type errors in the code itself as defined by the PEPs.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code would fail at runtime. ",
            "has_runtime_error": true,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to find and analyze the Python file, thus reporting no issues and missing the identified type error.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "Here's a detailed analysis of the provided code for type safety issues:\n\nISSUE 1: Incompatible type argument for list append\n  - Line: 65 (commented out in the provided code)\n  - Rule: Type compatibility for list elements. An element being appended to a `List[X]` must be a subtype of `X`.\n  - PEP Reference: PEP 484, \"Type variables\" (implied by generic types and subtyping), \"Subtype relationships\".\n  - Should Error: YES\n\nExplanation:\nThe class variable `_registered_instances` is defined as `List[Self]`. When `IntConfigurator` inherits this, `IntConfigurator._registered_instances` is correctly interpreted by type checkers as `List[IntConfigurator]` (following the spirit of PEP 673 where `Self` resolves to the concrete, specialized type).\n`s1` is an instance of `StrConfigurator`. `StrConfigurator` is not a subtype of `IntConfigurator` (they are sibling classes inheriting from `BaseConfigurator` with different generic specializations). Attempting to append an object of type `StrConfigurator` to a list typed `List[IntConfigurator]` is a type error.\n\n**Analysis of other points (reveal_type and method access):**\n\n*   **Line 10: `_registered_instances: List[Self] = []`**\n    *   This declaration itself is type-safe according to PEP 673. The `Self` type is designed to refer to the current class (or concrete subclass when inherited). For class variables, when accessed through a subclass (e.g., `IntConfigurator._registered_instances`), `Self` is expected to resolve to that specific subclass type (`IntConfigurator`). This allows the \"registry\" pattern to work correctly and type-safely.\n\n*   **Line 55: `reveal_type(IntConfigurator._registered_instances)`**\n    *   Based on PEP 673's guidelines for `Self` in generic classes (where `Self` refers to the *specialized type*), a type checker should correctly infer the type as `List[IntConfigurator]`. This is the intended and most useful interpretation for maintaining type safety in this pattern.\n\n*   **Line 56: `reveal_type(StrConfigurator._registered_instances)`**\n    *   Similarly, a type checker should infer this as `List[StrConfigurator]`.\n\n*   **Line 60: `print(f\"First int config specific value: {first_int_config.get_specific_int_value()}\")`**\n    *   Given the correct interpretation of `IntConfigurator._registered_instances` as `List[IntConfigurator]`, `first_int_config` will be inferred as `IntConfigurator`. `IntConfigurator` defines the method `get_specific_int_value()`. Therefore, this line is type-safe. If `Self` were *not* correctly resolved (e.g., `first_int_config` was inferred as `BaseConfigurator[int]`), this line *would* be a type error because `BaseConfigurator` does not have `get_specific_int_value()`. However, standard type checkers following PEP 673 would resolve `Self` correctly here.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "PARTIAL",
            "reason": "The checker correctly identified that `List[Self]` for a shared class variable leads to issues with type compatibility during `append` operations and produces unsound revealed types for the shared list, but it failed to flag an unsafe attribute access on a potentially heterogeneous list element.",
            "accuracy": "Caught 3/5 real issues",
            "analysis": "This code contains several type safety issues stemming primarily from the use of `Self` with a shared class variable in a generic inheritance hierarchy. The fundamental conflict is between the runtime behavior of a single shared class list and the type system's potential for per-subclass specialization through `Self`.\n\nHere's a breakdown of the type safety violations:\n\nISSUE 1: Incompatible type annotation for shared class variable.\n  - Line: 5\n  - Rule: The class variable `_registered_instances` is declared with type `List[Self]` in `BaseConfigurator`. At runtime, `_registered_instances` is a single list object shared by `BaseConfigurator` and all its subclasses unless explicitly overridden in a subclass. As `IntConfigurator` and `StrConfigurator` instances are appended to this *same list* via `type(self)._registered_instances.append(self)`, the list will contain elements of both `IntConfigurator` and `StrConfigurator` types.\n    The annotation `List[Self]` in `BaseConfigurator` suggests that `_registered_instances` holds `BaseConfigurator` objects. However, if `Self` were to re-specialize per subclass for access (e.g., `IntConfigurator._registered_instances` as `List[IntConfigurator]`), it creates a type contradiction with the actual runtime content (which includes `StrConfigurator` objects). A type-safe annotation for a truly shared class variable intended to hold instances of diverse subclasses should be a common supertype that encompasses all possible contained types, such as `List[BaseConfigurator[Any]]` or `List[BaseConfigurator[Union[int, str]]]`. The current `List[Self]` implies a homogeneity that is violated by the shared state.\n  - PEP Reference: PEP 673 (Self, specifically its interaction with inherited class variables), PEP 484 (Type Compatibility, Liskov Substitution Principle, Class Variables).\n  - Should Error: YES. A type checker should emit a warning or error, indicating that `List[Self]` is problematic for a shared class variable that accumulates instances of different subclasses, as it leads to an unsound type.\n\nISSUE 2: `reveal_type(IntConfigurator._registered_instances)` provides an unsound type.\n  - Line: 38\n  - Rule: Due to `_registered_instances` being a single, shared list that contains both `IntConfigurator` and `StrConfigurator` instances at runtime, its most accurate and sound type is `List[BaseConfigurator[Union[int, str]]]` or `List[BaseConfigurator[Any]]`. If a type checker reports `List[IntConfigurator]` (implying `Self` fully re-specialized) or `List[BaseConfigurator[int]]` (implying specialization of `T` but not acknowledging other types), it provides an unsound type that does not reflect the actual runtime contents of the shared list, leading to potential downstream errors.\n  - PEP Reference: PEP 484 (Type Soundness, Generics, TypeVar variance).\n  - Should Error: YES. The type checker should report a type that correctly reflects the heterogeneous content of the shared list, typically a union type or `Any` for the generic argument.\n\nISSUE 3: `reveal_type(StrConfigurator._registered_instances)` provides an unsound type.\n  - Line: 39\n  - Rule: Similar to Issue 2, if the type checker reports `List[StrConfigurator]` or `List[BaseConfigurator[str]]`, it is unsound because the shared list also contains `IntConfigurator` instances. The most specific sound type would be `List[BaseConfigurator[Union[int, str]]]`.\n  - PEP Reference: PEP 484 (Type Soundness, Generics, TypeVar variance).\n  - Should Error: YES. Similar to Issue 2.\n\nISSUE 4: Accessing subclass-specific method on an insufficiently specialized type.\n  - Line: 47\n  - Rule: `first_int_config` is retrieved from `IntConfigurator._registered_instances`. As established, the list `_registered_instances` is shared and contains instances of both `IntConfigurator` and `StrConfigurator`. Therefore, `first_int_config` must be typed as `BaseConfigurator[Union[int, str]]` (or `BaseConfigurator[Any]`) or `Union[IntConfigurator, StrConfigurator]`. The method `get_specific_int_value()` exists only on `IntConfigurator`. Calling it directly on `first_int_config` without a preceding type narrowing check (e.g., `isinstance(first_int_config, IntConfigurator)`) is a type safety violation. At runtime, if `first_int_config` happens to be a `StrConfigurator` (which is possible if the order of appends changed), this line would raise an `AttributeError`.\n  - PEP Reference: PEP 484 (Attribute Access, Liskov Substitution Principle).\n  - Should Error: YES. A type checker must flag this as an invalid attribute access.\n\nISSUE 5: Appending an incompatible generic type to a list potentially specialized for a different generic argument.\n  - Line: 52 (commented out: `IntConfigurator._registered_instances.append(s1)`)\n  - Rule: `s1` is of type `StrConfigurator`, which is a `BaseConfigurator[str]`. If a type checker were to infer `IntConfigurator._registered_instances` as `List[BaseConfigurator[int]]` (reflecting a specialization of the generic parameter `T` when accessed through `IntConfigurator`), then attempting to append `s1` (a `BaseConfigurator[str]`) would be a type error. This is because `TypeVar T` is invariant by default in `BaseConfigurator`, meaning `BaseConfigurator[str]` is not a subtype of `BaseConfigurator[int]`. Even though at runtime the list is shared and already contains a mix, if the type checker tries to maintain a specialized view based on the access point, this append operation would violate that specialized view.\n  - PEP Reference: PEP 484 (Type Compatibility, TypeVar variance - specifically the default invariance of `TypeVar`).\n  - Should Error: YES. This should be caught as a type mismatch based on `TypeVar` invariance.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "self-in-protocol-default-implementation.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/self-in-protocol-default-implementation.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "PARTIAL",
            "reason": "Mypy correctly identified the primary type mismatch within the protocol's default method's return type (Issue 1) but then failed to report the subsequent attribute access errors (Issues 3 & 4) that are a direct consequence of the initial type inconsistency and the actual runtime behavior, despite its own revealed type suggesting these attributes would not be present.",
            "accuracy": "Caught 1/3 real issues",
            "analysis": "Here's a detailed analysis of the provided code for type safety issues:\n\nISSUE 1: The default implementation of `BaseCloneable.clone` violates its declared return type `Self`.\n  - Line: 17 (`return self.__copy__()`)\n  - Rule: Protocol implementation mismatch. A default method provided within a `Protocol` must satisfy its own declared signature for any concrete class that implicitly inherits it. In `BaseCloneable[T]`, the `clone` method is declared to return `Self` (the type of the concrete instance). Its default implementation `return self.__copy__()` returns a value of type `T` (from `__copy__`). When a class like `ConcreteCloneable` implements `BaseCloneable[str]`, `Self` becomes `ConcreteCloneable` while `T` becomes `str`. Therefore, the inherited `clone` method would actually return `str`, which is not `ConcreteCloneable`, violating the `-> Self` contract.\n  - PEP Reference: PEP 544 (Protocols, \"Implementation of a protocol\"), PEP 673 (Self type). Specifically, PEP 544 states: \"A concrete class `C` is considered to implement a protocol `P` if `C` implements all protocol members of `P`.\" When `C` inherits a default implementation from `P`, that inherited method must conform to the protocol's requirements for `C`.\n  - Should Error: YES. This is the root cause of the type unsafety. A type checker should identify this inconsistency within the protocol's default method definition.\n\nISSUE 2: Type inference for `cloned_obj` is unsound due to the protocol implementation flaw.\n  - Line: 40 (`reveal_type(cloned_obj)`)\n  - Rule: Unsound type inference. If the type checker does not catch Issue 1 at the protocol definition, it will likely infer the type of `cloned_obj` based on the *declared* return type of `BaseCloneable[str].clone`, which is `Self` (meaning `ConcreteCloneable` or `SubConcreteCloneable` depending on the runtime type of `obj`). However, as established in Issue 1, the *actual* runtime type returned by the default `clone` implementation for `ConcreteCloneable` and `SubConcreteCloneable` is `str`. This discrepancy leads to an unsound type system where the static type does not match the runtime type.\n  - PEP Reference: PEP 484 (Type Hints, \"Soundness considerations\"). Type checkers aim for soundness to prevent runtime type errors.\n  - Should Error: YES (indirectly, by revealing the consequence of not catching Issue 1). A `reveal_type` showing `ConcreteCloneable | SubConcreteCloneable` while the runtime type is `str` indicates a severe problem with the type system's ability to track correctness.\n\nISSUE 3: Unreachable code and potential `AttributeError` when accessing `cloned_obj._value`.\n  - Line: 43 (`if isinstance(cloned_obj, ConcreteCloneable):`) and 45 (`print(f\"Cloned object value: {cloned_obj._value}\")`)\n  - Rule: Type narrowing and attribute access. If `cloned_obj` is `str` at runtime (due to the underlying implementation issue, see Issue 1), then the `isinstance(cloned_obj, ConcreteCloneable)` check will always evaluate to `False`. This makes the code inside the `if` block unreachable. Furthermore, attempting to access `cloned_obj._value` on a `str` object would result in an `AttributeError` at runtime.\n  - PEP Reference: PEP 484 (Type Hints, \"Type narrowing with `isinstance()`\"), PEP 586 (Type Checking for `isinstance()` and `issubclass()`).\n  - Should Error: YES. If the type checker correctly infers `cloned_obj` as `str`, it should warn about unreachable code or an `AttributeError` on line 45. If it incorrectly infers `ConcreteCloneable | SubConcreteCloneable`, it would miss this error, highlighting its failure to detect Issue 1.\n\nISSUE 4: Unreachable code and potential `AttributeError` when accessing `cloned_obj.get_original_value()`.\n  - Line: 48 (`if isinstance(cloned_obj, SubConcreteCloneable):`) and 49 (`print(f\"Cloned object original value: {cloned_obj.get_original_value()}\")`)\n  - Rule: Type narrowing and attribute access. Similar to Issue 3, if `cloned_obj` is `str` at runtime, this `isinstance` check will always be `False`, making the code unreachable. Attempting to call `get_original_value()` on a `str` object would result in an `AttributeError`.\n  - PEP Reference: PEP 484, PEP 586.\n  - Should Error: YES. For the same reasons as Issue 3.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "PARTIAL",
            "reason": "The type checker correctly identified the primary unsoundness in the protocol's default method signature but failed to detect the downstream consequences in implementing classes, method calls, and control flow.",
            "accuracy": "Caught 1/4 real issues",
            "analysis": "This code contains several type safety issues stemming from the interaction of `Protocol` default methods, `Self`, and generic type variables.\n\nHere's a breakdown of the violations:\n\nISSUE 1: Incompatible return type in protocol's default method implementation.\n  - Line: 17 (`return self.__copy__()`)\n  - Rule: The `clone` method in `BaseCloneable[T]` is declared to return `Self` (`def clone(self) -> Self:`). However, its default implementation `return self.__copy__()` returns a value of type `T` (since `__copy__` is declared `-> T`). `T` is not guaranteed to be compatible with `Self`. For example, if `T` is bound to `str` and `Self` refers to a class like `ConcreteCloneable`, then `str` is not a subtype of `ConcreteCloneable`. This violates the rule that default method implementations within a `Protocol` must conform to their declared signatures.\n  - PEP Reference: PEP 544, \"Default implementations in Protocols\" (states that methods with default implementations must conform to their type signatures); PEP 484, \"Function and method types\" (describes return type compatibility).\n  - Should Error: YES. This is a fundamental type error within the protocol definition itself, making the protocol unsound.\n\nISSUE 2: Violation of protocol implementation contract by concrete classes inheriting the unsound default method.\n  - Line: 24 (implicit, at `class ConcreteCloneable(BaseCloneable[str]):`) and 35 (implicit, at `class SubConcreteCloneable(ConcreteCloneable):`)\n  - Rule: `ConcreteCloneable` implements `BaseCloneable[str]`. This means `T` is `str`. The inherited `clone` method from `BaseCloneable` has a signature `def clone(self) -> Self`. For `ConcreteCloneable`, `Self` resolves to `ConcreteCloneable`. However, the inherited implementation `return self.__copy__()` returns `str` (as `T` is `str` and `ConcreteCloneable.__copy__` returns `str`). Since `str` is not a subtype of `ConcreteCloneable`, `ConcreteCloneable` (and similarly `SubConcreteCloneable`) does not correctly implement the `clone` method of `BaseCloneable[str]`.\n  - PEP Reference: PEP 544, \"Implementing a protocol\" (a class implementing a protocol must provide methods with compatible signatures); PEP 484, \"Subtype relations\".\n  - Should Error: YES. A type checker should report that `ConcreteCloneable` (and `SubConcreteCloneable`) does not fully satisfy the `BaseCloneable[str]` protocol due to the type incompatibility of its `clone` method's effective return type.\n\nISSUE 3: Runtime type of returned value from a protocol method call does not match its static type.\n  - Line: 41 (`cloned_obj = obj.clone()`)\n  - Rule: When `obj` is typed as `BaseCloneable[str]`, calling `obj.clone()` should statically return a value of type `BaseCloneable[str]`. This is because, according to PEP 673, when a method returning `Self` is called on an instance whose static type is a protocol type, `Self` refers to the protocol type itself. However, at runtime, due to the unsound implementation discussed in ISSUE 1 and inherited by `ConcreteCloneable` (and `SubConcreteCloneable`), `obj.clone()` will actually return a `str` instance. `str` is not a subtype of `BaseCloneable[str]`, which is a direct violation of type soundness.\n  - PEP Reference: PEP 484, \"Basic principles\" (type checkers aim to ensure type soundness); PEP 673, \"Self parameter for classes and protocols\" (specifies how `Self` resolves on protocol instances).\n  - Should Error: YES. This is a crucial type safety violation at the call site. The type checker should detect that the actual runtime type of the value produced (`str`) does not conform to its statically inferred type (`BaseCloneable[str]`).\n\nISSUE 4: Unreachable code due to type mismatch.\n  - Line: 48 (`if isinstance(cloned_obj, ConcreteCloneable):`) and 52 (`if isinstance(cloned_obj, SubConcreteCloneable):`)\n  - Rule: As a direct consequence of ISSUE 3, `cloned_obj` is a `str` at runtime. Therefore, the conditions `isinstance(cloned_obj, ConcreteCloneable)` and `isinstance(cloned_obj, SubConcreteCloneable)` will always evaluate to `False`. The code branches within these `if` statements are thus unreachable. While not a direct \"type safety violation\" in the sense of causing a runtime type error *within* the branches (as they won't be executed), it indicates a logical flaw and a type checker could flag these as always-false conditions, potentially suggesting dead code.\n  - PEP Reference: Not a specific PEP on unreachable code, but implied by type system's ability to reason about control flow and types (e.g., in strict mode, some type checkers may warn about dead branches).\n  - Should Error: YES (as a warning). A type checker that correctly infers the runtime type of `cloned_obj` (due to ISSUE 3) should be able to identify these branches as unreachable.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker reported \"No Python files found to check\", indicating it failed to even start analyzing the provided code, and consequently missed all the significant type safety issues present.",
            "accuracy": "Caught 0/4 real issues",
            "analysis": "The provided Python code contains several type safety issues related to the use of `Protocol`, `Self`, and `TypeVar` with default method implementations.\n\nHere's a detailed analysis:\n\nISSUE 1: Incompatible return type in `BaseCloneable.clone`'s default implementation.\n  - Line: 18\n  - Rule: A default method implementation within a `Protocol` must conform to its declared signature, considering the protocol's generic parameters and `Self` type. Here, `clone` is declared to return `Self`, but its implementation `return self.__copy__()` returns `T`. `T` is a `TypeVar` generic parameter of `BaseCloneable`, while `Self` refers to the exact type of the instance implementing the protocol. There is no guarantee that `T` is assignable to `Self` in general, leading to a type mismatch. For example, if `BaseCloneable[str]` is implemented, `T` becomes `str`, and `Self` becomes the concrete class (e.g., `ConcreteCloneable`). `str` is not assignable to `ConcreteCloneable`.\n  - PEP Reference: PEP 544 (Protocols), specifically the rules for \"Class implementations of protocols\" and \"Default implementations\". PEP 673 (Self Type), which defines `Self` as referring to the current class/protocol type.\n  - Should Error: YES. A type checker should flag this as a fundamental type incompatibility within the protocol's own default implementation.\n\nISSUE 2: Concrete classes implicitly inherit an unsafe default `clone` method, violating the protocol contract.\n  - Line: 23 (Implicit, as `ConcreteCloneable` does not override `clone` and thus uses the default from `BaseCloneable[str]`)\n  - Line: 30 (Implicit, as `SubConcreteCloneable` does not override `clone` and thus uses the default from `BaseCloneable[str]`)\n  - Rule: When a concrete class implements a protocol (even by inheriting a default implementation), all its methods must conform to their declared types from the protocol.\n    *   For `ConcreteCloneable(BaseCloneable[str])`: `Self` resolves to `ConcreteCloneable`, and `T` resolves to `str`. The protocol declares `clone` as `() -> Self`. However, the inherited implementation calls `self.__copy__()`, which for `ConcreteCloneable` returns `str`. Thus, `clone` effectively returns `str` where `ConcreteCloneable` is expected, violating the protocol contract for `ConcreteCloneable`.\n    *   The same applies to `SubConcreteCloneable`, where `clone` should return `SubConcreteCloneable` but effectively returns `str`.\n  - PEP Reference: PEP 544 (Protocols), specifically \"Class implementations of protocols\". PEP 673 (Self Type).\n  - Should Error: YES. Type checkers should report that `ConcreteCloneable` (and `SubConcreteCloneable`) does not correctly implement the `BaseCloneable[str]` protocol due to the type incompatibility in the inherited `clone` method.\n\nISSUE 3: Incorrect type inference for `cloned_obj` in `test_cloneable`.\n  - Line: 37 (`reveal_type(cloned_obj)`)\n  - Rule: The `reveal_type` statement highlights the discrepancy between the expected return type (the specific `Self` type of `obj`, e.g., `ConcreteCloneable` or `SubConcreteCloneable`) and the actual return type (which is `str` due to the issues described above). While `reveal_type` itself is not an error, the fact that the type checker infers `str` (based on the actual, problematic implementation) instead of `Self` indicates a type violation. The type checker correctly deduces the actual return type of the method in the concrete instances.\n  - PEP Reference: PEP 484 (Type Hints) for type inference, PEP 544 (Protocols), PEP 673 (Self Type).\n  - Should Error: YES. The type checker should at least report that the return type of `obj.clone()` (which resolves to `str`) is not compatible with the declared `Self` type from the `BaseCloneable` protocol, which is the underlying cause for this mis-inference.\n\nISSUE 4: Unreachable code and invalid attribute access in `test_cloneable`.\n  - Line: 41 (`print(f\"Cloned object value: {cloned_obj._value}\")`)\n  - Line: 46 (`print(f\"Cloned object original value: {cloned_obj.get_original_value()}\")`)\n  - Rule: Type checkers perform control flow analysis and type narrowing with constructs like `isinstance`.\n    *   Given that `cloned_obj` is inferred to be `str` (as per Issue 3, reflecting the actual return of the problematic `clone` implementation), the conditions `isinstance(cloned_obj, ConcreteCloneable)` and `isinstance(cloned_obj, SubConcreteCloneable)` will always evaluate to `False`. This makes the code inside these `if` blocks unreachable.\n    *   Attempting to access `_value` (specific to `ConcreteCloneable`) or `get_original_value()` (specific to `SubConcreteCloneable`) on an object known to be `str` will lead to an `AttributeError` at runtime.\n  - PEP Reference: PEP 647 (Type Guard) for `isinstance` narrowing rules, PEP 484 (Type Hints) for attribute access validation.\n  - Should Error: YES. A type checker should report unreachable code and/or attribute access errors on `str` objects that do not possess the accessed attributes.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker's output shows only an informational `reveal_type` message and no diagnostics, indicating it failed to identify any of the fundamental type safety violations, including the critical unsoundness in the protocol's default implementation and subsequent runtime errors.",
            "accuracy": "Caught 0/4 real issues",
            "analysis": "Here's a detailed analysis of the provided code for type safety violations:\n\nISSUE 1: **Inconsistent return type in `BaseCloneable.clone`'s default implementation.**\n  - Line: 19\n  - Rule: A protocol method's default implementation must conform to its own declared signature. The default implementation of `BaseCloneable.clone` returns `self.__copy__()`, which has type `T`. However, the `clone` method is declared to return `Self`. In the general context of `BaseCloneable[T]`, the generic type parameter `T` is not generally assignable to `Self` (which represents the instance of the protocol itself, i.e., `BaseCloneable[T]`). For instance, if `T` is `str`, `Self` is `BaseCloneable[str]`; `str` is not assignable to `BaseCloneable[str]`.\n  - PEP Reference: PEP 544, \"Protocols and structural subtyping\", section \"Default implementations\". This section states: \"If a protocol member has a default implementation, a subtype can either inherit the default implementation or provide its own. In both cases, the member must be compatible with the protocol definition.\" This implies the default implementation itself must be compatible with its own signature.\n  - Should Error: YES. This is a fundamental type safety violation within the protocol's definition, leading to unsoundness if not caught.\n\nISSUE 2: **Type Mismatch at Call Site due to Inherited Protocol Default Implementation.**\n  - Line: 36 (`cloned_obj = obj.clone()`)\n  - Rule: When a concrete class like `ConcreteCloneable` (or `SubConcreteCloneable`) inherits the default `clone` method from `BaseCloneable`, its effective implementation calls `self.__copy__()`. For `ConcreteCloneable`, `self.__copy__()` is overridden to return `str`. Therefore, `ConcreteCloneable.clone()` *actually* returns a `str` object at runtime. However, the inherited signature from `BaseCloneable` dictates that `ConcreteCloneable.clone()` should return `Self` (i.e., `ConcreteCloneable`). Returning `str` when `ConcreteCloneable` is expected constitutes a type mismatch.\n  - PEP Reference: PEP 484, \"Type Hints\", Section \"Soundness\" (implied, as type checkers aim to ensure runtime types match static types) and PEP 544, \"Protocols and structural subtyping\" (conformance of implementations to protocol definitions). This issue is a direct consequence of Issue 1; even if Issue 1 is not flagged, this manifestation at the call site should be.\n  - Should Error: YES. This is a critical runtime type safety violation that type checkers are designed to detect. The statically inferred type of `cloned_obj` (e.g., `ConcreteCloneable` or `BaseCloneable[str]`) will not match its runtime type (`str`).\n\nISSUE 3: **Incompatible attribute access in `test_cloneable` (ConcreteCloneable branch).**\n  - Line: 40 (`print(f\"Cloned object value: {cloned_obj._value}\")`)\n  - Rule: Due to Issue 2, `cloned_obj` will be of type `str` at runtime. The `_value` attribute is specific to `ConcreteCloneable` instances. Attempting to access `_value` on a `str` object will result in an `AttributeError` at runtime. Furthermore, if the type checker correctly infers `cloned_obj` as `str`, it would know that `isinstance(str, ConcreteCloneable)` (line 38) is always `False`, making this code branch unreachable.\n  - PEP Reference: PEP 484, \"Type Hints\" (Type safety and attribute access).\n  - Should Error: YES. A type checker should report an `AttributeError` for accessing `_value` on `str`, or report the `if` condition as always false and the branch as unreachable.\n\nISSUE 4: **Incompatible method call in `test_cloneable` (SubConcreteCloneable branch).**\n  - Line: 44 (`print(f\"Cloned object original value: {cloned_obj.get_original_value()}\")`)\n  - Rule: Similar to Issue 3, `cloned_obj` will be of type `str` at runtime. The `get_original_value()` method is specific to `SubConcreteCloneable` instances. Attempting to call this method on a `str` object will result in an `AttributeError` at runtime. If the type checker correctly infers `cloned_obj` as `str`, it would know that `isinstance(str, SubConcreteCloneable)` (line 43) is always `False`, making this code branch unreachable.\n  - PEP Reference: PEP 484, \"Type Hints\" (Type safety and method calls).\n  - Should Error: YES. A type checker should report an `AttributeError` for calling `get_original_value()` on `str`, or report the `if` condition as always false and the branch as unreachable.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "pep-695-alias-union-generic-methods.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/pep-695-alias-union-generic-methods.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "INCORRECT",
            "reason": "Mypy reported no issues, completely missing the attribute access error on a union type that was identified in the analysis.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Attempt to call a method that is not guaranteed to exist on all members of a union type.\n  - Line: 48\n  - Rule: Attribute access on a union type. When an attribute or method is accessed on a value typed as a `Union`, a type checker must verify that all constituents of the `Union` possess that attribute or method with a compatible signature, unless the type has been explicitly narrowed. In this case, `service` is typed as `MixedService`, which is `GenericReader[int] | StringProcessor`. The method `read_one()` exists on `GenericReader[int]` but not on `StringProcessor`. Therefore, accessing `service.read_one()` without narrowing `service` to `GenericReader[int]` specifically is a potential `AttributeError` at runtime.\n  - PEP Reference: PEP 484, \"The Union Type\" section. The principle states that \"When a value of a Union type is dereferenced, the type checker will assume that all constituents of the Union have the requested attribute or method, and if not, it will issue an error.\"\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "CORRECT",
            "reason": "The type checker correctly reported zero errors for the active code, and all inferred types for `reveal_type` calls matched the analysis, demonstrating correct handling of union type narrowing. The potential issue on line 41 was commented out, so the checker correctly did not flag it as an error.",
            "accuracy": "Caught 0/0 real issues (the identified issue was on a commented-out line and thus not an active error in the provided code).",
            "analysis": "ISSUE 1: Attempting to call a method (`read_one`) on a union type (`MixedService`) where that method is not guaranteed to exist on all members of the union without prior type narrowing.\n\n- Line: 41 (referencing the commented-out line that demonstrates the issue)\n- Rule: Attribute access on a union type is only valid if the attribute exists on all members of the union, or if the type has been sufficiently narrowed (e.g., using `isinstance`) to a type where the attribute is guaranteed to exist. In this case, `StringProcessor` (a member of `MixedService`) does not have a `read_one` method.\n- PEP Reference: PEP 484, \"Union types\" section (implicitly, as part of general static type checking rules for attribute access and method calls on composite types). This rule is a fundamental aspect of ensuring static type consistency and preventing `AttributeError` at runtime. PEP 647 on \"User-Defined Type Guards\" (and built-in `isinstance`) exists precisely to enable safe attribute access on narrowed union types, implying that such access is unsafe without narrowing.\n- Should Error: YES. A type checker should report an error here, indicating that `StringProcessor` has no attribute `read_one`.\n\n---\n\n**Note on `reveal_type` calls:** The `reveal_type` calls in the provided code are not type safety violations themselves. They are tools used by type checkers to show the inferred type at a specific point.\n- Inside the `if isinstance(service, GenericReader):` block (lines 28-30), `service` is correctly narrowed to `GenericReader[int]`. Therefore, `reveal_type(service.read_one())` should show `int`, and `reveal_type(service.get_data_length())` should show `int`.\n- Inside the `elif isinstance(service, StringProcessor):` block (lines 31-33), `service` is correctly narrowed to `StringProcessor`. Therefore, `reveal_type(service.process_string(\"abc\"))` should show `str`, and `reveal_type(service.get_prefix_length())` should show `int`.\n- Inside the `if isinstance(mixed_instance, GenericReader):` block (line 53), `mixed_instance` is correctly narrowed to `GenericReader[int]`. Therefore, `reveal_type(mixed_instance.read_one())` should show `int`.\n\nAll these `reveal_type` expectations are consistent with correct type narrowing and attribute access. The code, as written and *executed* (excluding the commented line), is type-safe due to the effective use of `isinstance` checks for narrowing the union types. The `try...except` block at the end merely handles a potential runtime `AttributeError` for a different scenario, but the static analysis of the code within that block (due to `isinstance`) is sound.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to find and process the Python file, therefore it could not detect any type issues.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Attempted attribute access on a union type without sufficient narrowing.\n  - Line: 46 (referring to the commented-out `reveal_type(service.read_one())` line as if it were active)\n  - Rule: When accessing a member (attribute or method) on an object typed as a `Union[A, B]`, the member must be present on *all* components of the union unless the type has been narrowed to a specific component. In this case, `read_one` exists on `GenericReader[int]` but not on `StringProcessor`.\n  - PEP Reference: PEP 484 - \"Union Types\", specifically the section \"Accessing members of a union type\".\n  - Should Error: YES. A type checker should report a type error, as accessing `service.read_one()` where `service` could be `StringProcessor` would lead to an `AttributeError` at runtime. The type `MixedService` is `GenericReader[int] | StringProcessor`, and `read_one` is not a common attribute.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker produced only informational `reveal_type` diagnostics and did not report the identified potential runtime `AttributeError` at line 43.",
            "accuracy": "0/1 real issues",
            "analysis": "ISSUE 1: Attempting to access an attribute (`read_one`) on a union type (`MixedService`) where that attribute is not guaranteed to exist on all constituent types of the union.\n\n*   Line: 43\n*   Rule: When accessing an attribute or method on a union type `Union[X, Y]`, that attribute/method must be present on *both* `X` and `Y`, unless the type of the variable has been narrowed through a type-checking construct (e.g., `isinstance`, `if-else` flow analysis). In this case, `read_one` exists on `GenericReader[int]` but not on `StringProcessor`.\n*   PEP Reference: PEP 484, \"Union Types\" section. Specifically, the implication that \"you can only access attributes and methods that are common to both X and Y\". This rule is fundamental to sound type checking with unions.\n*   Should Error: YES. This will lead to an `AttributeError` at runtime if `service` happens to be a `StringProcessor` instance. A type checker should flag this as a potential runtime error. The PEP 695 alias syntax does not change this fundamental rule of union types.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "overload-decorator-any-refined.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/overload-decorator-any-refined.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker correctly inferred `Any` for the affected variables (as confirmed by `reveal_type` notes), which validated the root cause of Issue 1, but it failed to report this type information loss or the subsequent unchecked attribute access (Issue 2) as errors, indicating \"Success: no issues found.\"",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "ISSUE 1: Type information loss for decorated generic overload\n  - Line: 22 (Application of `@identity_decorator` on the third overload of `create`)\n  - Rule: When a decorator is typed with `Any` in its signature, type checkers may correctly infer `Any` for the decorated function's signature, losing specific type information such as generic `TypeVar` bindings. In this case, `identity_decorator(f: Any) -> Any` signals that the decorator accepts and returns a function of `Any` type. When applied to `create(item_type: type[T], config: dict[str, Any]) -> T`, this weak decorator signature causes the specific generic type `T` to be lost. Consequently, the return type for calls to this overload (e.g., `Factory.create(Product, {\"version\": 1})`) is inferred as `Any`, rather than `Product`.\n  - PEP Reference: PEP 484 (Section \"The `Any` type\" which describes its role in type checking, and \"Decorated functions\" which states decorators' type annotations are used for inference). Implicitly, PEP 612 (`ParamSpec`) highlights that specific mechanisms are needed to preserve full function signatures through decorators, which `Any` does not achieve.\n  - Should Error: YES. The subsequent call `product_instance.get_name()` (line 44) attempts to access an attribute on what the type checker now considers `Any`. This is an unchecked operation that subverts static type checking, which type checkers are designed to report to ensure type safety.\n\nISSUE 2: Unchecked attribute access due to `Any` inference\n  - Line: 44 (`product_instance.get_name()`)\n  - Rule: Attempting to access attributes or call methods on a variable that has been inferred as `Any` circumvents static type checking. This means the type checker cannot verify if `get_name` actually exists on the runtime type of `product_instance`, leading to a potential `AttributeError` at runtime without compile-time detection. This directly results from the type information loss described in Issue 1.\n  - PEP Reference: PEP 484 (Section \"The `Any` type\", which explicitly states that `Any` is compatible with all types and all types are compatible with `Any`, thus disabling type checks for operations involving `Any`).\n  - Should Error: YES. Type checkers typically flag unchecked attribute access on `Any` as an error or a strict warning, as it bypasses the core purpose of type hints.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker completely missed the explicitly identified usage error and showed significant failures in type inference, frequently reporting `Unknown` where specific types or `Any` should have been resolved.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Decorator on an @overload stub.\n  - Line: 29\n  - Rule: Decorators on `@overload` stubs are not supported by type checkers unless they are specific built-in decorators like `@classmethod`, `@staticmethod`, or `@abstractmethod`. The `identity_decorator` is a custom decorator and thus violates this rule. Type checkers are expected to ignore such unsupported decorators on overload stubs.\n  - PEP Reference: PEP 484, \"Function Overloading\" section.\n  - Should Error: YES (A type checker should report this as a usage error or warning, even if it ignores the decorator for type inference.)\n\nNO OTHER ISSUES: The remaining code is type-safe according to the specified PEPs.\n*   The `identity_decorator`'s signature `(f: Any) -> Any` is intentionally broad and correctly typed for its purpose.\n*   The different `@overload` signatures are well-formed and compatible with the single implementation signature `def create(*args: Any, **kwargs: Any) -> Any`.\n*   The implementation logic correctly handles the various input types implied by the overloads, producing the corresponding return types.\n*   The use of `Any` in `identity_decorator` and the catch-all overload for `create` are explicit choices to allow flexibility, not type safety violations.\n*   The type inference for `Factory.create(Product, {\"version\": 1})` should correctly resolve `T` to `Product`, returning `Product` (assuming the type checker correctly ignores the unsupported `identity_decorator` on the overload stub, as per PEP 484).\n*   The construct `args[0]()` when `args[0]` is of type `type[T]` is considered type-safe, as it's assumed `T` is instantiable with no arguments unless explicitly constrained otherwise (e.g., by being an abstract class or protocol that's explicitly not instantiable). For `Product`, this is valid.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to execute the analysis, reporting that it could not find the file, and therefore could not provide any type-checking results to compare with the analysis.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\n**Explanation:**\n\nThe provided Python code, including its type hints, does not contain any type safety violations according to the specified PEPs (484, 544, 586, 589, 647).\n\n1.  **Overload Definitions and Implementation (PEP 484):**\n    *   The use of `@overload` for `Factory.create` is correct. Multiple overloads are defined, followed by a single, general implementation.\n    *   The implementation `def create(*args: Any, **kwargs: Any) -> Any:` is sufficiently general to be compatible with all preceding overload stubs, as `Any` is compatible with all types for both arguments and return values.\n    *   Each branch within the implementation correctly handles the specific argument types corresponding to an overload and returns a type compatible with the specific overload's return type (e.g., `str` for `str` overload, `int` for `int` overload, `T()` returning `T` for the generic overload).\n\n2.  **`identity_decorator` and its impact on typing (PEP 484):**\n    *   The `identity_decorator` is defined with the signature `(f: Any) -> Any`. This is a valid type annotation for a decorator that takes any callable and returns it without any specific type guarantees or modifications.\n    *   When applied to the `@overload` stub `create(item_type: type[T], config: dict[str, Any]) -> T: ...`, the decorator's own signature (using `Any`) does not inherently constitute a *type safety violation*.\n    *   While this signature *might* lead some less sophisticated type checkers to infer `Any` for `product_instance` (as noted in the code's comments), this would be an *inference limitation* of the type checker, not a *violation* of the code's annotations. The explicit `@overload` stub clearly states `-> T`, and a robust type checker should prioritize this specific stub's return type for overload resolution, especially given that `identity_decorator` is a pass-through.\n    *   Since `Product` *does* have a `get_name()` method, the call `product_instance.get_name()` is valid at runtime. Even if `product_instance` were inferred as `Any`, it wouldn't expose a runtime error in this specific instance. Therefore, no actual type safety violation is present due to the decorator.\n\n3.  **TypeVars and Generics (PEP 484):**\n    *   `T = TypeVar(\"T\")` is correctly defined and used in the generic overload `create(item_type: type[T], config: dict[str, Any]) -> T`.\n\n4.  **Calls to `Factory.create`:**\n    *   All calls in `test_factory` correctly match their intended overloads or fall into the `Any` catch-all, and `reveal_type` would confirm the expected types (`str`, `int`, `Product`, `Any`).\n\nIn summary, the type annotations in the code are internally consistent, and the runtime behavior aligns with the static types, without any contradictions or situations that should lead to a type checker error.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "PARTIAL",
            "reason": "The type checker reported a general `invalid-overload` error due to the code's problematic overload structure, which resulted in `Any` inference for all `create` calls (including the one involving the decorated overload), but it did not specifically identify the decorator placement on the `@overload` definition as an issue.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Incorrect application of a signature-modifying decorator on an `@overload` definition.\n  - Line: 25 (`@identity_decorator`)\n  - Rule: PEP 484 states that decorators which modify the decorated function's signature (i.e., do not preserve it with a generic signature) can *only* be applied to the final (non-overload) implementation. The `identity_decorator` is defined as `(f: Any) -> Any`, which does not preserve the specific generic signature of the third `@overload` definition (`(item_type: type[T], config: dict[str, Any]) -> T`). Applying such a decorator to an `@overload` that is not the implementation violates this guideline. This can lead to type checkers either erroring on the decorator placement or inferring `Any` for the decorated overload's return type, losing specific type information.\n  - PEP Reference: PEP 484 -- Type Hints, section \"Stubs for functions and methods\" (specifically the paragraph concerning \"Decorators on overloaded functions need to be handled carefully.\").\n  - Should Error: YES. A type checker *should* report this as an invalid usage, as it directly contravenes the guidelines for decorators on overloaded functions. If not flagged, it can lead to type inference issues (e.g., `Any` being inferred for `product_instance` instead of `Product`), silently reducing type safety.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "typeguard-generic-dict-narrowing.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/typeguard-generic-dict-narrowing.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "CORRECT",
            "reason": "Both the analysis and the type checker confirmed that the code is type-safe, correctly handles `TypeGuard` with generic dictionary types, and performs the expected type narrowing and chaining.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\n### Analysis:\nThe provided code demonstrates a sophisticated and generally type-safe use of `TypeGuard` with generic dictionary types. My analysis confirms that the code adheres to Python typing rules as defined in PEP 484 and especially PEP 647 (TypeGuard).\n\nHere's a breakdown of the key elements and why they are considered type-safe:\n\n1.  **`TypeVar` Usage (K, V)**: The `TypeVar` `K` is used correctly to parameterize the key type of the dictionary in the `TypeGuard` functions. This ensures that the key type is preserved during the narrowing process, which is a correct and powerful application of generics with `TypeGuard`.\n2.  **`TypeGuard` Definitions**:\n    *   `is_dict_of_data_records(d: Dict[K, Any]) -> TypeGuard[Dict[K, DataRecord]]`: The input type `Dict[K, Any]` is a supertype of the target type `Dict[K, DataRecord]`. The implementation `all(isinstance(v, DataRecord) for v in d.values())` correctly checks the runtime type of the values. This `TypeGuard` is correctly defined to narrow `Any` values to `DataRecord`.\n    *   `is_dict_of_validated_records(d: Dict[K, DataRecord]) -> TypeGuard[Dict[K, ValidatedDataRecord]]`: Similarly, `Dict[K, DataRecord]` is a supertype of `Dict[K, ValidatedDataRecord]`, given that `ValidatedDataRecord` is a subclass of `DataRecord`. The `isinstance` check is also correct. This `TypeGuard` is correctly defined to further narrow `DataRecord` values to `ValidatedDataRecord`.\n3.  **`TypeGuard` Chaining and Narrowing**:\n    *   The core of the \"DISAGREEMENT POINT\" in the original code comments lies in whether type checkers can correctly chain `TypeGuard`s, especially when dealing with generic types where only a type parameter (like the value type of a `Dict`) is narrowed.\n    *   According to PEP 647, \"Type checkers should use the return type `TypeGuard[X]` to infer that the guarded expression is of type `X` if the function returns `True`.\" This statement implies that if a `TypeGuard` is correctly defined (as these are), the type checker *should* apply the narrowing as specified.\n    *   In `process_data_dicts`:\n        *   After `if is_dict_of_data_records(data):`, `data` is correctly narrowed from `Dict[str, Any]` to `Dict[str, DataRecord]`.\n        *   Within that block, if `is_dict_of_validated_records(data)` is true, the `data` (which is currently `Dict[str, DataRecord]`) should logically be further narrowed to `Dict[str, ValidatedDataRecord]`. This chaining is a direct application of `TypeGuard`'s principle. Accessing `v.is_valid()` after this narrowing is type-safe because `v` is correctly inferred as `ValidatedDataRecord`.\n    *   Any failure by a type checker to perform this chaining and generic type parameter narrowing would be a limitation of the type checker's implementation, not a violation of type safety rules in the code itself. The code correctly expresses the desired type transformations.\n\n4.  **Runtime Behavior**: The `isinstance` checks accurately reflect the type annotations, ensuring that the runtime behavior matches the static type-narrowing expectations.\n\nThe code is well-structured and demonstrates a robust pattern for runtime type checking and static type narrowing using `TypeGuard` for complex generic types.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "CORRECT",
            "reason": "The type checker's output perfectly aligns with the analysis, confirming that the code is type-safe and correctly handles the chaining of generic TypeGuards as expected by PEP 647.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\n**Analysis:**\nThe provided code demonstrates correct and idiomatic usage of `TypeGuard` with generic types (`TypeVar` and `Dict`).\n\n1.  **`is_dict_of_data_records` TypeGuard**:\n    *   It correctly defines `K` as a `TypeVar` to preserve the dictionary's key type.\n    *   The input `d: Dict[K, Any]` allows for narrowing the value type from `Any`.\n    *   The return type `TypeGuard[Dict[K, DataRecord]]` correctly indicates that if the guard returns `True`, the `Any` value type will be narrowed to `DataRecord`, while preserving the specific `K` type inferred from the call site.\n    *   The implementation `all(isinstance(v, DataRecord) for v in d.values())` correctly performs the runtime check.\n\n2.  **`is_dict_of_validated_records` TypeGuard**:\n    *   Similar to the first, it correctly uses `K` to preserve the key type.\n    *   The input `d: Dict[K, DataRecord]` expects `DataRecord` values, indicating it's intended for further narrowing.\n    *   The return type `TypeGuard[Dict[K, ValidatedDataRecord]]` correctly indicates that if the guard returns `True`, the `DataRecord` value type will be narrowed to `ValidatedDataRecord`, preserving `K`.\n    *   The implementation `all(isinstance(v, ValidatedDataRecord) for v in d.values())` correctly performs the runtime check.\n\n3.  **`process_data_dicts` Function and Chaining of TypeGuards**:\n    *   When `is_dict_of_data_records(data)` is called, if `True`, `data` is correctly narrowed from `Dict[str, Any]` to `Dict[str, DataRecord]`. The `reveal_type` should confirm this.\n    *   Subsequently, when `is_dict_of_validated_records(data)` is called (with `data` now being `Dict[str, DataRecord]`), if `True`, `data` should be further narrowed to `Dict[str, ValidatedDataRecord]`.\n    *   This chaining of TypeGuards on generic types, where the TypeVar `K` is consistently preserved, is the intended behavior as per PEP 647. Modern type checkers (like MyPy and Pyright) are expected to handle this scenario correctly, reflecting `Dict[str, ValidatedDataRecord]` after the second guard. The \"DISAGREEMENT POINT\" noted in the original code comments refers to potential limitations or bugs in certain type checker *implementations* rather than a violation of the Python typing specification itself. From a PEP perspective, this code is correctly annotated.\n    *   All attribute and method accesses (`v.get_name()`, `v.is_valid()`) within the `if` blocks are safe due to the type narrowing provided by the `TypeGuard`s.\n\nAll assignments and operations in the `if __name__ == \"__main__\":` block are also type-consistent with their declarations and the expected behavior of the `process_data_dicts` function. The various test cases correctly illustrate the different paths and narrowing outcomes.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "CORRECT",
            "reason": "The type checker reported no type issues, which aligns with the analysis that the code is type-safe. However, this outcome is due to the checker failing to locate the file for analysis, rather than a successful type check.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\nThe provided code adheres to Python's type system rules, including those introduced by PEP 647 for `TypeGuard`. The use of `TypeGuard` with generic types like `Dict[K, V]` correctly preserves the key type `K` while narrowing the value type. The chained application of `TypeGuard`s to progressively narrow the value type (from `Any` to `DataRecord`, then `DataRecord` to `ValidatedDataRecord`) is a valid and intended use case according to PEP 647.\n\nSpecifically:\n1.  **Generic TypeVars (`K`, `V`):** These are correctly defined and used in the `TypeGuard` signatures to ensure that the key type of the dictionary is preserved during narrowing, which is a key feature of generic `TypeGuard`s.\n2.  **`is_dict_of_data_records`:** This `TypeGuard` correctly narrows `Dict[K, Any]` to `Dict[K, DataRecord]`. The implementation uses `isinstance` checks against `DataRecord`, which is consistent with the `TypeGuard`'s return type.\n3.  **`is_dict_of_validated_records`:** This `TypeGuard` correctly narrows `Dict[K, DataRecord]` to `Dict[K, ValidatedDataRecord]`. The input type `Dict[K, DataRecord]` is compatible with the type after the first `TypeGuard` application, and the implementation uses `isinstance` checks against `ValidatedDataRecord`, a subtype of `DataRecord`.\n4.  **Chaining of TypeGuards:** Within `process_data_dicts`, the nested `if` statements demonstrate a valid chaining of `TypeGuard` applications. After the first `TypeGuard` (`is_dict_of_data_records(data)`), the type of `data` becomes `Dict[str, DataRecord]`. When the second `TypeGuard` (`is_dict_of_validated_records(data)`) is applied, `data` (already `Dict[str, DataRecord]`) is further narrowed to `Dict[str, ValidatedDataRecord]` if the condition holds. This behavior is explicitly supported by PEP 647, which states: \"Type guards interact with subtyping and generics in a natural way.\" (e.g., `list[object]` -> `list[int]`).\n5.  **Method Access:** All method calls (`get_name()`, `is_valid()`) are performed on objects whose types have been appropriately narrowed by the `TypeGuard`s, making these accesses type-safe within their respective `if` blocks.\n\nThe expectations for `reveal_type` in the comments are consistent with how a compliant type checker should interpret the type narrowing provided by these `TypeGuard`s.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "PARTIAL",
            "reason": "My analysis assumed the code was type-safe due to effective TypeGuards; the checker's `reveal_type` indicated these TypeGuards were not effective for its analysis, but it then failed to report the attribute access errors that would logically follow from its own type inference.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "overload-decorator-return-type-divergence.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/overload-decorator-return-type-divergence.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "PARTIAL",
            "reason": "Mypy correctly ignored the potential unhashable key issue due to the use of `Any`, but it missed the critical PEP 484 violation regarding decorators on overload stubs.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "Here's an analysis of the provided code for type safety issues, adhering strictly to Python typing rules and PEPs, and ignoring in-code comments regarding type checker behavior:\n\nISSUE 1: Decorator applied to an `@overload` stub\n  - Line: 38 (`@caching_decorator`)\n  - Rule: Decorators other than `@overload` itself should only be applied to the implementation of the overloaded function, not to individual overload stubs. Applying a decorator to an overload stub implies a transformation of that specific signature, but PEP 484 advises against this pattern. If the intent is for `caching_decorator` to actually modify the runtime behavior of `DataService.fetch` for a specific call pattern, it cannot be achieved by decorating an overload stub; decorators affect the function's implementation.\n  - PEP Reference: PEP 484, \"Function Overloading\" section, states: \"Decorators other than @overload itself, e.g. @abstractmethod, should only be applied to the implementation.\"\n  - Should Error: YES. A type checker adhering strictly to PEP 484 should flag this as an incorrect decorator placement.\n\nISSUE 2: Potential runtime `TypeError` due to unhashable dictionary keys.\n  - Line: 19 (`key = (args, tuple(sorted(kwargs.items())))`)\n  - Rule: Dictionary keys must be hashable. The type of `args` is `P.args`, which is a `tuple` where each element's type corresponds to the positional arguments of the decorated function. If any of these positional arguments are of an unhashable type (e.g., `list`, `dict`, `set`), then the `args` tuple itself becomes unhashable. Consequently, the `key` tuple (which includes `args`) would also be unhashable, leading to a `TypeError` at runtime when attempting to use it as a key in the `cache` dictionary.\n  - PEP Reference: General Python runtime rules for dictionary keys, implied by the existence of `typing.Hashable` in PEP 484 (though `Hashable` is not used here).\n  - Should Error: NO. The `cache` dictionary is typed as `dict[Any, R]`. The use of `Any` for the key type explicitly signals to type checkers that no static checks on the key's type (including hashability) should be performed. While this masks a potential runtime type safety issue, it is compliant with the behavior defined for `Any`.\n\n---\n**Further implications (not explicit issues, but consequences of Issue 1):**\n\nIf a type checker *correctly* identifies Issue 1 and consequently ignores the `@caching_decorator` on the overload stub for type checking purposes:\n*   The third overload for `DataService.fetch` would be interpreted as having the return type `dict[str, Any]` (as declared on line 39).\n*   The implementation for this branch (lines 49-53) returns `dict[str, Any]`, which is fully compatible with the interpreted overload signature.\n*   Therefore, the `reveal_type(result_decorated_call1)` on line 68 would show `dict[str, Any]`. The expectation in the inline comment regarding a `tuple[dict[str, Any], bool]` return type would be incorrect based on a strict PEP 484 interpretation.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker reported \"0 errors\" despite two significant type safety issues identified, indicating a complete failure to catch the problems.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "Here's an analysis of the provided Python code for type safety issues:\n\nISSUE 1: Incompatible return type in the implementation for a decorated `@overload` signature.\n  - Line: 59 (the `return` statement within the `elif len(args) >= 1 and isinstance(args[0], str):` block)\n  - Rule: The implementation of an overloaded function must be type-compatible with all of its declared `@overload` signatures. When a decorator that transforms a function's type (like `caching_decorator`) is applied to an `@overload` declaration, it modifies the expected static type of that specific overload. The implementation must then satisfy this modified type.\n    - The `caching_decorator` transforms `Callable[P, R]` to `Callable[P, tuple[R, bool]]`.\n    - Applied to `@overload @staticmethod def fetch(...) -> dict[str, Any]: ...` (lines 35-37), the decorator transforms its declared return type from `dict[str, Any]` to `tuple[dict[str, Any], bool]`.\n    - The corresponding implementation path (lines 55-59) for this overload returns `dict[str, Any]`.\n    - `dict[str, Any]` is not compatible with `tuple[dict[str, Any], bool]`.\n  - PEP Reference: PEP 484, \"Overloading\" section, which states, \"Type checkers should allow the last (non-`@overload`) definition to implement all the preceding `@overload` definitions.\" This implies strict compatibility.\n  - Should Error: YES. If a type checker respects decorators on `@overload` declarations (which is a reasonable interpretation of placing a decorator there), this is a fundamental mismatch.\n\nISSUE 2: Decorator applied to an `@overload` declaration without corresponding runtime effect.\n  - Line: 36 (`@caching_decorator`)\n  - Rule: Applying a decorator to an `@overload` declaration (which is a type-hinting construct, not the runtime implementation) typically has no effect on the runtime behavior of the actual function implementation. This creates a divergence where the static type analysis (if the decorator is honored) suggests a certain runtime behavior (e.g., caching and a transformed return type) that will not actually occur because the decorator is not applied to the function's runtime definition. This leads to a false sense of type safety or incorrect assumptions about the program's behavior. While not a direct \"type mismatch\" in the sense of assigning an incompatible type, it's a structural issue that leads to incorrect type inferences relative to runtime behavior.\n  - PEP Reference: While PEP 484 defines `@overload`, it does not explicitly define the semantics of decorators on `@overload` declarations. However, the core principle of type hints is to reflect runtime behavior. This construct violates that principle.\n  - Should Error: YES (or at least a strong warning). A type checker should alert developers to this common pitfall, as it indicates a likely misunderstanding of how decorators interact with `@overload` declarations. The intended caching effect will not happen, despite the type hints suggesting it would (if the decorator's effect on the overload is honored).\n\nThe remaining `reveal_type` calls and other parts of the code appear consistent with expected type inference, assuming the type checker handles `ParamSpec` correctly and the first two overloads are straightforward. The \"catch-all\" overload correctly captures calls that don't match more specific ones.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker reported that it found no Python files to check, therefore it missed the only identified type safety issue.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "Here's an analysis of the provided code for type safety issues, based on Python typing rules and PEPs:\n\nISSUE 1: Decorator applied to an `@overload` stub has no effect\n  - Line: 40 (`@caching_decorator`)\n  - Rule: According to PEP 612 (ParamSpec), \"Decorators on `@overload` stubs are ignored. If a decorator applies to an overloaded function, it should be applied to the implementation. In this case, it applies to all overloads of the function.\" This means that the `@caching_decorator` placed on the `@overload` stub for `DataService.fetch` (the third overload) will be ignored by static type checkers, and its logic will not be applied at runtime. Consequently, the type transformation from `R` to `tuple[R, bool]` that `caching_decorator` performs will not occur for this specific overload, either during type checking or at runtime. The `reveal_type` for calls matching this overload will correctly infer `dict[str, Any]` (the return type declared on the stub, without the decorator's effect), and the runtime execution will return `dict[str, Any]`, not a tuple. This creates a significant discrepancy between the implied intent of the decorator's presence and the actual static and runtime behavior of the code.\n  - PEP Reference: PEP 612, \"Decorators\" section.\n  - Should Error: YES. A type checker should issue a warning or error for a decorator applied to an `@overload` stub. This signals that the decorator is a no-op in this context, prevents misinterpretations by developers who might expect the decorator's type transformation or runtime logic to be applied, and highlights a likely misunderstanding of how decorators interact with `overload`. This is crucial for maintaining type safety by ensuring that type hints accurately reflect runtime behavior.\n\nNO OTHER ISSUES:\nThe remaining parts of the code are generally type-safe:\n- The `caching_decorator` function itself is correctly typed using `ParamSpec` and `TypeVar` to transform the return type.\n- The cache key type `Any` is acceptable for a complex, generic key structure like `(args, tuple(sorted(kwargs.items())))`.\n- The `DataService.fetch` implementation correctly handles argument parsing and returns types compatible with its *undecorated* overload signatures.\n- The `reveal_type` calls, assuming a type checker adhering to PEP 612, will correctly infer the types (`str`, `list[str]`, `dict[str, Any]`, `Any`), even if the `dict[str, Any]` for the decorated overload is contrary to the author's implied intention in the `DISAGREEMENT POINT` comment.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to correctly interpret the `@overload` definitions and the effect of decorators on them, resulting in a false positive error and `Any` inferences that masked the identified type safety violation.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "The code presents a critical type safety issue related to the application of a decorator to an `@overload` signature.\n\nISSUE 1: **Type mismatch due to decorator on `@overload` signature.**\n  - Line: 35\n  - Rule: Type checkers are specified to ignore decorators applied to `@overload` definitions for type inference. However, at runtime, the decorator *will* be applied, transforming the function's actual return type. This creates a discrepancy between the static type inferred by the type checker and the actual runtime type.\n    In this specific case, the type checker will infer the return type of `DataService.fetch(\"products\", ...)` as `dict[str, Any]` (from the third overload's signature). At runtime, due to `caching_decorator`, the function will return `tuple[dict[str, Any], bool]`. This is a type safety violation as the runtime value does not conform to the statically inferred type.\n  - PEP Reference: PEP 484, Section \"Function Overload\" states: \"Decorators on `@overload` definitions are ignored by type checkers. The decorator on the implementation definition is used.\"\n  - Should Error: YES. A type checker *should* report this as a type error or a strong warning. Specifically, it should either:\n    1.  Warn that the decorator on the `@overload` signature is ignored and thus will not affect the inferred type.\n    2.  If the code later attempts to use the result (e.g., `result_decorated_call1['key']`), and the inferred type is `dict[str, Any]` while the runtime value is a `tuple`, it should flag a type error for accessing a dictionary key on a tuple. The `reveal_type` calls at lines 71 and 74 would show `dict[str, Any]` statically, even though the runtime value is a `tuple`. This reveals the violation.\n\nNo other type safety issues were found. The use of `ParamSpec` in `caching_decorator` is correct for preserving parameter types, and the `DataService.fetch` implementation correctly adheres to the non-decorated overload signatures. The use of `Any` for cache keys and in the catch-all overload is permissible and serves its intended purpose without introducing new violations.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "newtype-generic-variance-refined.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/newtype-generic-variance-refined.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "PARTIAL",
            "reason": "The type checker correctly identified one invariant generic type mismatch (Issue 3), but did not report errors for two other distinct type mismatches identified in the analysis (Issues 1 and 2), likely because those specific lines were not active in the code processed by the checker.",
            "accuracy": "Caught 1/3 real issues",
            "analysis": "Here's a type safety analysis of the provided Python code:\n\nISSUE 1: Attempt to pass `CustomerId` to a method expecting `OrderId`.\n  - Line: Approximately 45 (if uncommented: `p.process(CustomerId(99))`)\n  - Rule: Type argument mismatch. `p` is an `IdProcessor[OrderId]`, so its `process` method expects an `OrderId`. `CustomerId` is a distinct `NewType` from `OrderId`, and therefore not a subtype of `OrderId`.\n  - PEP Reference: PEP 484, \"Subtyping\" and \"NewType\". `NewType` creates distinct types that are subtypes of their base type, but not of other `NewType`s based on the same or different base types.\n  - Should Error: YES\n\nISSUE 2: Attempt to pass `IdProcessor[CustomerId]` where `IdProcessor[OrderId]` is expected.\n  - Line: Approximately 71 (if uncommented: `process_id_type(customer_processor, CustomerId(456))`)\n  - Rule: Incompatible type for function parameter. The function `process_id_type` expects an argument of type `IdProcessor[OrderId]`. The variable `customer_processor` has type `IdProcessor[CustomerId]`. Since `T` in `IdProcessor[T]` is defined as `T = TypeVar(\"T\", bound=int)` (which is invariant by default), `IdProcessor[CustomerId]` is not considered a subtype of `IdProcessor[OrderId]`.\n  - PEP Reference: PEP 484, \"Generics\" and \"Covariant and Contravariant Type Variables\". PEP 484 states: \"By default, a generic type `Foo[T]` is invariant with respect to `T`. To declare a generic type as covariant or contravariant, a type variable must be declared with `covariant=True` or `contravariant=True`.\"\n  - Should Error: YES\n\nISSUE 3: Passing `IdProcessor[OrderId]` where `IdProcessor[int]` is expected.\n  - Line: 88 (`process_int_type(order_processor, OrderId(100))`)\n  - Rule: Incompatible type for function parameter. The function `process_int_type` expects an argument of type `IdProcessor[int]`. The variable `order_processor` has type `IdProcessor[OrderId]`. As established in Issue 2, `T` is an invariant `TypeVar`. Therefore, `IdProcessor[OrderId]` is not a subtype of `IdProcessor[int]`, even though `OrderId` is a subtype of `int`. If `IdProcessor` were declared as contravariant (e.g., using `T = TypeVar(\"T\", bound=int, contravariant=True)`), then `IdProcessor[int]` would be a subtype of `IdProcessor[OrderId]`, but the reverse would not be true, and this assignment would still be an error.\n  - PEP Reference: PEP 484, \"Generics\" and \"Covariant and Contravariant Type Variables\".\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "CORRECT",
            "reason": "The type checker correctly identified the single type incompatibility present in the executed code, aligning perfectly with the analysis's prediction for that specific issue.",
            "accuracy": "Caught 1/1 real issues",
            "analysis": "Here's an analysis of the provided code for type safety issues, based on Python typing rules and PEPs:\n\nISSUE 1: Incompatible type argument for `process` method\n  - Line: `p.process(CustomerId(99))` (hypothetical, if uncommented in `process_id_type`)\n  - Rule: Type compatibility. The `process` method of `IdProcessor[OrderId]` expects an argument of type `OrderId`. `CustomerId` is a distinct `NewType` from `OrderId`, and thus `CustomerId` is not a subtype of `OrderId`.\n  - PEP Reference: PEP 484, \"Subtyping\"\n  - Should Error: YES\n\nISSUE 2: Incompatible generic type for function argument\n  - Line: `process_id_type(customer_processor, CustomerId(456))` (hypothetical, if uncommented in `if __name__ == \"__main__\":`)\n  - Rule: Type compatibility. The `process_id_type` function expects its first argument `p` to be of type `IdProcessor[OrderId]`. `customer_processor` is inferred as `IdProcessor[CustomerId]`. Since `OrderId` and `CustomerId` are distinct `NewType`s, `IdProcessor[CustomerId]` is not compatible with `IdProcessor[OrderId]` (regardless of variance, as `CustomerId` is not a subtype of `OrderId` and vice versa).\n  - PEP Reference: PEP 484, \"Subtyping\", \"Variance\"\n  - Should Error: YES\n\nISSUE 3: Incompatible generic type for function argument due to variance\n  - Line: `process_int_type(order_processor, OrderId(100))`\n  - Rule: Type compatibility (for argument `p`).\n    - The `IdProcessor` class uses `T` exclusively in contravariant positions (as an argument type for `ProcessorFunc[T]` in `__init__` and `item_id: T` in `process`). Therefore, `IdProcessor` is conceptually contravariant in `T`.\n    - If a generic type `P` is contravariant in `T`, then if `S` is a subtype of `U` (`S <: U`), it follows that `P[U]` is a subtype of `P[S]` (`P[U] <: P[S]`).\n    - In this case, `OrderId` is a subtype of `int` (`OrderId <: int`).\n    - Thus, `IdProcessor[int]` is a subtype of `IdProcessor[OrderId]` (`IdProcessor[int] <: IdProcessor[OrderId]`).\n    - The `process_int_type` function expects `p: IdProcessor[int]`.\n    - We are passing `order_processor`, which is `IdProcessor[OrderId]`.\n    - This is an attempt to assign a supertype (`IdProcessor[OrderId]`) where a subtype (`IdProcessor[int]`) is expected. This is a type error.\n    - (Note: Even if `IdProcessor` were treated as invariant by default, `IdProcessor[OrderId]` would not be compatible with `IdProcessor[int]`, leading to the same error for a different reason.)\n  - PEP Reference: PEP 484, \"Variance\" (specifically the rule for contravariance), \"Subtyping\"\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker reported \"No Python files found,\" indicating it failed to analyze the provided code and therefore missed the identified type error.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Type mismatch in function call due to invariant TypeVar\n  - Line: 80\n  - Rule: Argument type mismatch for a generic class instance where the TypeVar is implicitly invariant. `IdProcessor[OrderId]` is not a subtype of `IdProcessor[int]`.\n  - PEP Reference: PEP 484, \"Variance of generic types\" (specifically, the default invariance), and \"Subtyping of generic types\".\n  - Should Error: YES\n\n**Explanation:**\n\n1.  **`TypeVar T` declaration**: The `TypeVar T = TypeVar(\"T\", bound=int)` is declared without an explicit variance modifier (`covariant=True` or `contravariant=True`). According to PEP 484, such `TypeVar`s are treated as **invariant** by default.\n\n2.  **`IdProcessor` instantiation**:\n    *   `order_processor = IdProcessor(format_order_id)` infers `T` as `OrderId`, making `order_processor` of type `IdProcessor[OrderId]`.\n    *   `generic_int_processor = IdProcessor(format_generic_int)` infers `T` as `int`, making `generic_int_processor` of type `IdProcessor[int]`.\n\n3.  **Function Call `process_int_type`**:\n    *   `process_int_type` is defined as `def process_int_type(p: IdProcessor[int], val: int):`. It expects the first argument `p` to be an instance of `IdProcessor[int]`.\n    *   On line 80, the call is `process_int_type(order_processor, OrderId(100))`.\n    *   The second argument, `OrderId(100)`, is assignable to `val: int` because `OrderId` is a `NewType` subtype of `int` (as per PEP 484, \"NewType\").\n    *   The first argument, `order_processor`, has the type `IdProcessor[OrderId]`.\n\n4.  **The Violation**:\n    *   Since `T` is invariant, `IdProcessor[OrderId]` is considered neither a subtype nor a supertype of `IdProcessor[int]`, unless `OrderId` and `int` are the exact same type. `OrderId` is a distinct `NewType`, so they are not the same type.\n    *   Therefore, `IdProcessor[OrderId]` cannot be assigned to a parameter expecting `IdProcessor[int]`. This is a type mismatch.\n\n**Note on intended variance vs. actual variance**:\nThe design of `IdProcessor` (where `T` is used as an input parameter for `process` and within the argument type of `__init__`'s `processor` parameter in a way that implies contravariance) suggests that `IdProcessor` *should* be contravariant in `T`. If `T` *were* explicitly declared as `TypeVar(\"T\", bound=int, contravariant=True)`, then `IdProcessor[int]` would be a subtype of `IdProcessor[OrderId]`. In that case, passing `IdProcessor[OrderId]` (the supertype) where `IdProcessor[int]` (the subtype) is expected would *still* be a type error, as assignment goes from subtype to supertype, not the other way around. Thus, the specific call on line 80 would be an error regardless of whether `T` is invariant or explicitly contravariant.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to report the identified type incompatibility at line 77, only providing informational revealed types.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Incompatible type assignment to a generic parameter.\n  - Line: 77\n  - Rule: A value of type `IdProcessor[OrderId]` is passed where an argument of type `IdProcessor[int]` is expected.\n    `NewType('OrderId', int)` is a distinct type from `int` for static type checking purposes, even though it's a runtime subtype.\n    The generic class `IdProcessor` is, by default, invariant in its type parameter `T` (as `T` is not declared with `covariant=True` or `contravariant=True`). Therefore, `IdProcessor[OrderId]` is neither a subtype nor a supertype of `IdProcessor[int]`.\n    Even if `IdProcessor` were explicitly marked as `contravariant` (which its structure suggests), `OrderId` being a subtype of `int` would mean `IdProcessor[int]` is a subtype of `IdProcessor[OrderId]`. In that scenario, passing the supertype `IdProcessor[OrderId]` where the subtype `IdProcessor[int]` is expected would still be a type error.\n  - PEP Reference: PEP 484, \"NewType\" (regarding distinctness of NewTypes) and \"Variance\" (regarding default invariance of generic types).\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "newtype-in-generic-class-with-covariance.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/newtype-in-generic-class-with-covariance.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "PARTIAL",
            "reason": "The checker correctly identified the inconsistent variance declaration for the `TypeVar` but failed to propagate the resulting effective invariance to a subsequent assignment involving a `NewType` and its base type. (Issues 2 and 4 were not checked as they were commented out).",
            "accuracy": "Caught 1/4 real issues",
            "analysis": "Here's a detailed analysis of the type safety issues in the provided code:\n\nISSUE 1: Inconsistent variance declaration for `TypeVar` in `DataLoader`\n  - Line: 8 (`Co = TypeVar(\"Co\", bound=int, covariant=True)`) and potentially 10 (`class DataLoader(Generic[Co]):`)\n  - Rule: A type variable declared as `covariant=True` must only appear in covariant positions within the generic class (e.g., return types, sequence element types). If it appears in contravariant positions (e.g., as a parameter in a method that consumes the type, like `__init__` or `add_id`), the declaration is inconsistent with the class's actual variance. The `DataLoader` class uses `Co` in the `__init__` parameter (`ids: List[Co]`) and `add_id` parameter (`new_id: Co`). `List[Co]` is invariant in `Co`, and a direct parameter `new_id: Co` is a contravariant position. This means `DataLoader` is effectively invariant with respect to `Co`, despite `Co` being declared `covariant=True`.\n  - PEP Reference: PEP 484, section \"Variance of type variables\". The PEP explicitly states, \"It is the responsibility of the user to declare type variables with the correct variance. Type checkers are expected to flag incorrect variance whenever they can detect it.\" It also provides an example of this exact violation.\n  - Should Error: YES (A type checker should either flag the `covariant=True` declaration as incorrect for this class implementation, or implicitly treat `DataLoader` as invariant, leading to subsequent errors if covariance is assumed).\n\nISSUE 2: Type incompatibility when adding `RecordId` to `DataLoader[EntityId]` (currently commented out)\n  - Line: 29 (`loader.add_id(RecordId(99))`)\n  - Rule: Argument type mismatch. The `loader` is explicitly typed as `DataLoader[EntityId]`, meaning its `add_id` method expects an argument of type `EntityId`. `RecordId(99)` is an instance of `RecordId`. `NewType`s, even if based on the same primitive type, are distinct and not interchangeable; `RecordId` is not a subtype of `EntityId`.\n  - PEP Reference: PEP 484, section \"NewType\" (\"`NewType` creates distinct types\" and \"Static type checkers should treat the new type as a subtype of the base type.\").\n  - Should Error: YES\n\nISSUE 3: Type incompatibility when passing `DataLoader[EntityId]` to a function expecting `DataLoader[int]`\n  - Line: 55 (`process_int_loader(entity_loader)`)\n  - Rule: Argument type incompatibility. `process_int_loader` expects an argument of type `DataLoader[int]`. `entity_loader` is of type `DataLoader[EntityId]`. As established in Issue 1, `DataLoader` is effectively *invariant* with respect to its type parameter `Co` because `Co` appears in contravariant positions. For an invariant generic type `G`, `G[S]` is only compatible with `G[T]` if `S` is precisely `T`. Since `EntityId` is not `int` (though it's a subtype of `int`), `DataLoader[EntityId]` is not a subtype of `DataLoader[int]`.\n  - PEP Reference: PEP 484, section \"Variance of type variables\".\n  - Should Error: YES\n\nISSUE 4: Type incompatibility when passing `DataLoader[RecordId]` to a function expecting `DataLoader[EntityId]` (currently commented out)\n  - Line: 59 (`process_entity_loader(record_loader)`)\n  - Rule: Argument type incompatibility. `process_entity_loader` expects an argument of type `DataLoader[EntityId]`. `record_loader` is of type `DataLoader[RecordId]`. `RecordId` is not a subtype of `EntityId` (they are distinct `NewType`s). Therefore, `DataLoader[RecordId]` cannot be assigned to `DataLoader[EntityId]`, regardless of `DataLoader`'s variance. If `DataLoader` is invariant (as established in Issue 1), this further confirms the incompatibility.\n  - PEP Reference: PEP 484, section \"NewType\" and \"Variance of type variables\".\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker reported zero errors, completely missing the critical type safety violations identified in the analysis, including the unsound covariant TypeVar declaration and the resulting potential for runtime type errors.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "Here's a type safety analysis of the provided code:\n\nISSUE 1: Incorrect variance declaration for `TypeVar` in `DataLoader`\n  - Line: 10 (`Co = TypeVar(\"Co\", bound=int, covariant=True)`) and subsequent usage within `DataLoader`\n  - Rule: A generic type should not be declared covariant if it has methods that accept arguments of the type variable, or if it stores mutable data of that type, as this creates a type hole.\n  - PEP Reference: PEP 484, \"Variance\" and \"Covariant and contravariant type variables\" sections. The principle is that mutable containers (`List[T]`) must be invariant because adding an element of a supertype would violate type safety if the container was treated as covariant.\n  - Should Error: YES. A type checker should report that `TypeVar 'Co'` appears in an invariant position (e.g., as an argument to `add_id` or within the mutable `_ids: List[Co]`). The `DataLoader` class, as defined, is fundamentally invariant due to its mutable `_ids` attribute and the `add_id` method. Declaring `Co` as `covariant=True` is unsound.\n\nISSUE 2: Type mismatch when adding an unrelated `NewType` to a `DataLoader`\n  - Line: 32 (`loader.add_id(RecordId(99))`) - *This line is commented out in the source.*\n  - Rule: `NewType` instances are distinct from other `NewType` instances, even if they share the same base type. A method expecting a specific `NewType` should not be called with an unrelated `NewType`.\n  - PEP Reference: PEP 484, \"NewType\" section. \"NewType instances are nominal types, meaning `EntityId` and `RecordId` are distinct types, not subtypes of each other.\"\n  - Should Error: YES. `loader` is `DataLoader[EntityId]`, so `add_id` expects `EntityId`. `RecordId(99)` is `RecordId`, which is not a subtype of `EntityId`.\n\nISSUE 3: Runtime type safety violation due to incorrect covariance declaration\n  - Line: 56 (`process_int_loader(entity_loader)`) leading to Line: 39 (`loader.add_id(100)`)\n  - Rule: If a type `Generic[S]` is passed to a function expecting `Generic[T]` where `S` is a subtype of `T`, and `Generic` is (unsoundly) declared covariant, then methods within `Generic[T]` that accept `T` can introduce `T` into `Generic[S]`, violating type safety.\n  - PEP Reference: PEP 484, \"Variance\" section. This issue directly arises from the unsound `covariant=True` declaration (Issue 1).\n  - Should Error: YES.\n    - When `process_int_loader(entity_loader)` is called, `entity_loader` (actual type: `DataLoader[EntityId]`) is treated as `DataLoader[int]` due to `Co` being declared `covariant=True` and `EntityId` being a subtype of `int`.\n    - Inside `process_int_loader`, `loader.add_id(100)` is called. Statically, `100` (an `int`) is compatible with `Co` because `loader` is considered `DataLoader[int]`.\n    - However, at runtime, the `loader` instance is `DataLoader[EntityId]`, meaning its `_ids` list expects `EntityId` instances. Attempting to append `100` (an `int`, not an `EntityId`) to `List[EntityId]` would lead to a runtime type error or unexpected behavior, as the list would contain a value of an incompatible type according to the original `DataLoader[EntityId]` typing.\n    - While the type checker *should* ideally flag Issue 1 (the class definition), if it doesn't, then this specific call should be flagged.\n\nISSUE 4: Type mismatch when assigning an unrelated `NewType` generic instance\n  - Line: 61 (`process_entity_loader(record_loader)`) - *This line is commented out in the source.*\n  - Rule: `NewType` instances are distinct. Generic types `Generic[X]` and `Generic[Y]` are not compatible if `X` and `Y` are unrelated, even if the base type of `X` and `Y` is the same and the `TypeVar` is covariant. Covariance only applies when `X` is a subtype of `Y`.\n  - PEP Reference: PEP 484, \"NewType\" section and \"Covariant and contravariant type variables\" section.\n  - Should Error: YES. `record_loader` is `DataLoader[RecordId]`, and `process_entity_loader` expects `DataLoader[EntityId]`. Since `RecordId` is not a subtype of `EntityId`, `DataLoader[RecordId]` is not a subtype of `DataLoader[EntityId]`.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to process the input file, resulting in no type errors reported despite two clear issues.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "ISSUE 1: Incompatible type for argument `new_id` in `DataLoader.add_id`\n  - Line: 29\n  - Rule: The `add_id` method of `loader` (which is typed as `DataLoader[EntityId]`) expects an argument of type `EntityId`. However, `RecordId(99)` is of type `RecordId`. `RecordId` is not a subtype of `EntityId`; `NewType`s, even when based on the same primitive, are distinct types.\n  - PEP Reference: PEP 484, \"Subtyping\" (specifically `NewType` behavior) and \"Function calls\".\n  - Should Error: YES\n\nISSUE 2: Incompatible generic type argument for function call `process_entity_loader`\n  - Line: 57\n  - Rule: The function `process_entity_loader` expects an argument of type `DataLoader[EntityId]`. The provided argument `record_loader` is of type `DataLoader[RecordId]`.\n    Since the type variable `Co` in `DataLoader` is declared as `covariant=True`, for `DataLoader[RecordId]` to be a subtype of `DataLoader[EntityId]`, `RecordId` must be a subtype of `EntityId`. This is not true; `EntityId` and `RecordId` are distinct types.\n  - PEP Reference: PEP 484, \"Generics\" (specifically \"Variance of type variables\") and \"Subtyping\" (for `NewType` distinctness).\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker 'ty' only reported `info[revealed-type]` messages and did not identify any actual type errors, missing both issues described in the analysis.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "Here's a detailed analysis of the provided code for type safety issues, ignoring comments as instructed:\n\nISSUE 1: Attempting to add a `RecordId` to a `DataLoader` specialized for `EntityId`.\n  - Line: (would be line 29 if uncommented)\n  - Rule: Argument type mismatch. The `add_id` method of `DataLoader[EntityId]` expects an argument of type `EntityId`. Providing a `RecordId` is a type violation because `RecordId` is a distinct `NewType` and is not a subtype of `EntityId`.\n  - PEP Reference: PEP 484, \"NewType\" section, which states that `NewType` creates distinct types that are subtypes of their base type, but not of other `NewType`s, even if they share the same base type.\n  - Should Error: YES\n\nISSUE 2: Attempting to pass a `DataLoader[RecordId]` to a function expecting `DataLoader[EntityId]`.\n  - Line: (would be line 60 if uncommented)\n  - Rule: Argument type mismatch for a generic function parameter. The `process_entity_loader` function expects `loader` to be of type `DataLoader[EntityId]`. Passing `record_loader` (which is `DataLoader[RecordId]`) is a type violation. While the `TypeVar` `Co` is declared `covariant=True`, this only allows `DataLoader[S]` to be assigned to `DataLoader[T]` if `S` is a subtype of `T`. Here, `RecordId` is not a subtype of `EntityId`.\n  - PEP Reference: PEP 484, \"The `TypeVar()` factory\" section (for covariance rules) and \"NewType\" section (for distinct types).\n  - Should Error: YES",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "generic-typevar-bound-with-protocol-and-self.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/generic-typevar-bound-with-protocol-and-self.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "PARTIAL",
            "reason": "My analysis concluded the code was type-safe, meaning there were no real issues. Mypy reported one error which, based on the Python typing specification (PEP 484), is a false positive regarding the interpretation of TypeVar bounds. The `reveal_type` outputs also indicate `mypy` did not fully specialize `T_Valued` to `MyValueClass` in `operate_processor`, though it correctly handled the `isinstance` narrowing.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\nThe provided code demonstrates correct and robust usage of advanced Python typing features, including `TypeVar` with bounds, `Protocol`s with default implementations, the `Self` type, generic abstract base classes, and type narrowing with `isinstance`. The \"DISAGREEMENT POINT\" comments in the source code seem to stem from a misunderstanding of how type variables resolve in generic functions or how `Self` operates, but the code's actual type behavior is sound.\n\nHere's a detailed analysis confirming its type safety:\n\n1.  **`T_Valued = TypeVar(\"T_Valued\", bound=\"ValueContainerProtocol\")` (Line 4)**: This correctly defines a `TypeVar` that must be a subtype of `ValueContainerProtocol`. This ensures that any type substituted for `T_Valued` will provide the attributes and methods defined in the protocol. (PEP 484, section \"Type Variables\")\n\n2.  **`ValueContainerProtocol` (Lines 6-13)**:\n    *   It defines `value: int`, which must be present in implementing classes.\n    *   `get_value` has a default implementation, which is allowed for protocols (PEP 544, section \"Protocols with concrete methods\").\n    *   `update_value(self, new_val: int) -> Self`: The use of `Self` here is correct. It ensures that this method, when called on an instance of a specific class (e.g., `MyValueClass`), will return an instance of that exact class. This is crucial for fluent interfaces and method chaining without losing type information. (PEP 673)\n\n3.  **`GenericProcessor[T_Valued]` (Lines 15-28)**:\n    *   This abstract class correctly uses `T_Valued` to parameterize the type of `_item` and the return type of `process_item`.\n    *   The `inspect_value` method correctly accesses `_item.get_value()`, which is guaranteed to exist due to `T_Valued` being bound by `ValueContainerProtocol`. (PEP 484, section \"Generics\")\n\n4.  **`ConcreteProcessor` (Lines 30-41)**:\n    *   `class ConcreteProcessor(GenericProcessor[\"MyValueClass\"])`: This correctly specializes the generic base class. For instances of `ConcreteProcessor`, `T_Valued` effectively becomes `MyValueClass`. (PEP 484, section \"Generics\")\n    *   `process_item(self) -> \"MyValueClass\"`: The return type `MyValueClass` is consistent with `GenericProcessor[T_Valued]` because, in this specialized context, `T_Valued` is `MyValueClass`.\n    *   Inside `process_item`: `self._item` has type `MyValueClass`. Calling `self._item.update_value(...)` correctly resolves `Self` to `MyValueClass`, so the expression returns `MyValueClass`. The subsequent `return self._item` (which is `MyValueClass`) is therefore type-consistent with the method's declared return type.\n\n5.  **`MyValueClass` (Lines 43-48)**:\n    *   `class MyValueClass(ValueContainerProtocol)`: This class correctly implements `ValueContainerProtocol` by having a `value` attribute and inheriting/implementing `get_value` and `update_value`.\n    *   `get_info()`: This is a specific method of `MyValueClass`, not part of the protocol.\n\n6.  **`operate_processor(proc: GenericProcessor[T_Valued])` (Lines 50-62)**:\n    *   When `operate_processor(cp)` is called, `cp` is `ConcreteProcessor`, which means `T_Valued` for this specific function invocation resolves to `MyValueClass`.\n    *   `reveal_type(proc._item)`: A type checker would reveal `MyValueClass` (since `T_Valued` is `MyValueClass` here), which is correct.\n    *   `reveal_type(inspected)`: `proc.inspect_value()` returns `int`, so `inspected` is `int`. Correct.\n    *   `processed_item = proc.process_item()`: `proc.process_item()` (which resolves to `ConcreteProcessor.process_item()`) returns `MyValueClass`. So `processed_item` is `MyValueClass`.\n        *   The comment `# DISAGREEMENT POINT: Expected T_Valued, might be broader like ValueContainerProtocol.` is incorrect. `T_Valued` *is* `MyValueClass` in this execution context.\n    *   `if isinstance(processed_item, MyValueClass)`: This is a correct use of a type guard. Inside this block, `processed_item` is correctly narrowed to `MyValueClass`. (PEP 647)\n    *   `print(f\"Processed item info: {processed_item.get_info()}\")`: Because `processed_item` is narrowed to `MyValueClass`, its `get_info()` method is safely accessible.\n        *   The comment `# DISAGREEMENT POINT` is unfounded, as the type narrowing makes this access safe.\n\n7.  **`AnotherValueClass` example (Lines 67-73)**:\n    *   The commented-out line `another_proc = GenericProcessor(AnotherValueClass(50))` would indeed cause a type error. `AnotherValueClass` does not explicitly inherit from `ValueContainerProtocol` and, more importantly, it is missing the `update_value` method with the correct signature. A type checker would correctly identify that `AnotherValueClass` does not satisfy the `ValueContainerProtocol` bound for `T_Valued`. (PEP 544, section \"Structural Subtyping\"). Since this line is commented out, it's not a violation in the *current* code.\n\nIn conclusion, the code demonstrates a sophisticated and type-safe design pattern using generics, protocols, and `Self`. All type annotations and operations are consistent with the specified PEPs.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "CORRECT",
            "reason": "The type checker correctly identified a `missing-attribute` error, demonstrating that the code was not type-safe, contrary to the initial analysis.",
            "accuracy": "Caught 1/1 real issues",
            "analysis": "NO ISSUES: Code is type-safe",
            "method": "multi_step"
          },
          {
            "verdict": "ERROR",
            "reason": "Runtime analysis failed",
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to locate the Python file and therefore could not perform any type analysis to confirm or contradict the given analysis, effectively failing to perform its task.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\nDetailed analysis confirms that the provided code adheres to Python's typing rules and PEPs. All uses of `TypeVar`, `Protocol`, `Generic`, `ABC`, and `Self` are correct and applied consistently.\n\nSpecifically:\n*   **TypeVar `T_Valued` bound by `ValueContainerProtocol`**: Correctly defines a type variable that must conform to the specified protocol (PEP 544, \"Type variables bound to protocols\").\n*   **`ValueContainerProtocol`**: Correctly defines a protocol with an attribute (`value: int`), a method with a default implementation (`get_value`), and a method using `Self` as a return type (`update_value`). Default implementations in protocols are allowed (PEP 544, \"Default implementations for protocol methods\"). The use of `Self` correctly indicates that the method returns an instance of the class/protocol it's called on (PEP 673, \"Type `Self`\").\n*   **`GenericProcessor[T_Valued]`**: Correctly defines an abstract generic class parameterized by `T_Valued`. The `_item` attribute is typed as `T_Valued`, allowing access to `ValueContainerProtocol` methods. The abstract method `process_item` correctly returns `T_Valued` (PEP 484, \"Generic types and abstract base classes\").\n*   **`ConcreteProcessor`**: Correctly specializes `GenericProcessor` with `MyValueClass`. Its `__init__` and `process_item` methods are correctly typed. In `process_item`, when `self._item.update_value(...)` is called, `Self` in `ValueContainerProtocol` correctly resolves to `MyValueClass` because `self._item` has the concrete type `MyValueClass`. The return type of `process_item` (`MyValueClass`) matches the specialization.\n*   **`MyValueClass`**: Correctly implements `ValueContainerProtocol` by having a `value: int` attribute and implicitly (or explicitly, if overridden) conforming to the methods.\n*   **`operate_processor` function**:\n    *   `proc._item` is correctly inferred as `T_Valued`.\n    *   `inspected` is correctly inferred as `int`.\n    *   `processed_item` is correctly inferred as `T_Valued`.\n    *   The `isinstance(processed_item, MyValueClass)` check is a standard runtime type narrowing technique. Inside the `if` block, type checkers correctly narrow `processed_item` to `MyValueClass`, allowing safe access to `processed_item.get_info()`. This is a type-safe pattern.\n\nAll comments indicating \"DISAGREEMENT POINT\" in the source code are resolved as type-safe under a correct understanding of how type checkers operate with generics and runtime checks. The `reveal_type` outcomes would reflect the types as determined by the type system, not necessarily a broader protocol type when a more specific TypeVar is in use.\n\nThe commented-out lines using `AnotherValueClass` correctly identify a scenario where a type checker *would* report an error, as `AnotherValueClass` does not fully satisfy `ValueContainerProtocol` (missing `update_value` or a compatible `Self` return type), but this code path is not active.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code would fail at runtime. ",
            "has_runtime_error": true,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker incorrectly flags a false positive regarding a guaranteed attribute on a TypeVar-bound generic type, indicating a misinterpretation of TypeVar bounds with protocols.",
            "accuracy": "Caught 0/0 real issues",
            "analysis": "NO ISSUES: Code is type-safe\n\nThe provided code demonstrates correct and advanced usage of Python's typing features, including `Protocol`, `TypeVar` with bounds, `Generic` classes, `ABC` with abstract methods, and the `Self` type.\n\nHere's a detailed breakdown of the type system's behavior for key points, especially regarding the \"DISAGREEMENT POINT\" noted in the code comments, to confirm type safety:\n\n1.  **`T_Valued` TypeVar Bound (Line 3):**\n    `T_Valued = TypeVar(\"T_Valued\", bound=\"ValueContainerProtocol\")`\n    This correctly establishes that any type substituted for `T_Valued` must be a subtype of `ValueContainerProtocol`. `MyValueClass` explicitly inherits `ValueContainerProtocol`, satisfying this bound.\n\n2.  **`ValueContainerProtocol` and `Self` (Lines 6-13):**\n    The protocol defines `value: int`, `get_value() -> int`, and `update_value(self, new_val: int) -> Self`.\n    *   The use of `Self` in `update_value` is correct according to PEP 673 (\"Self type\"). When `MyValueClass` implements this protocol (either explicitly or implicitly), `Self` within the context of `MyValueClass` resolves to `MyValueClass`.\n    *   Default implementations for protocol methods (`get_value`, `update_value`) are allowed by PEP 544 (\"Protocol Members\").\n\n3.  **`GenericProcessor[T_Valued]` (Lines 15-28):**\n    This abstract class correctly uses `T_Valued` as its type parameter, ensuring that its `_item` attribute is of a type that satisfies `ValueContainerProtocol`. The `inspect_value` method correctly accesses `_item.get_value()`, which is guaranteed by the `T_Valued` bound.\n\n4.  **`ConcreteProcessor` Specialization (Lines 30-41):**\n    `class ConcreteProcessor(GenericProcessor[\"MyValueClass\"])`\n    This explicitly specializes `GenericProcessor`, effectively setting `T_Valued` to `MyValueClass` for this concrete implementation. Since `MyValueClass` implements `ValueContainerProtocol`, the `TypeVar` bound for `T_Valued` is satisfied.\n    *   The `__init__` method correctly expects `item: MyValueClass`.\n    *   The `process_item` method's implementation:\n        *   `self._item.update_value(...)`: `self._item` is `MyValueClass`. `MyValueClass` inherits `update_value` from `ValueContainerProtocol`. In the context of `MyValueClass`, `Self` resolves to `MyValueClass`, so `self._item.update_value(...)` returns `MyValueClass`.\n        *   `return self._item`: Returns `MyValueClass`.\n        *   The method's return type `-> \"MyValueClass\"` matches the actual return type. This is type-safe.\n\n5.  **`operate_processor` Function (Lines 51-64):**\n    `def operate_processor(proc: GenericProcessor[T_Valued]):`\n    When `operate_processor(cp)` is called with `cp: ConcreteProcessor`, type inference determines that for this specific call, the `T_Valued` in the function's signature is specialized to `MyValueClass` (because `ConcreteProcessor` is `GenericProcessor[MyValueClass]`).\n\n    *   `reveal_type(proc._item)` (Line 57):\n        *   `proc._item` is of type `T_Valued`. Given the specialization, `T_Valued` is `MyValueClass`.\n        *   *Expected type checker output:* `MyValueClass`.\n\n    *   `processed_item = proc.process_item()` (Line 60):\n        *   `proc.process_item()` returns `T_Valued`. Given the specialization, `T_Valued` is `MyValueClass`.\n        *   *Expected type checker output for `reveal_type(processed_item)`:* `MyValueClass`.\n        *   The comment `# DISAGREEMENT POINT: Expected T_Valued, might be broader like ValueContainerProtocol.` describes a potential weakness or error in a type checker's inference, not a type safety violation in the code itself. A compliant type checker, following PEP 484's rules for `TypeVar` inference in generic types, *should* infer `MyValueClass`.\n\n    *   `if isinstance(processed_item, MyValueClass):` (Line 63):\n        *   This `isinstance` check correctly narrows `processed_item` to `MyValueClass` within the `if` block.\n        *   `print(f\"Processed item info: {processed_item.get_info()}\")`: Inside the `if` block, `processed_item` is known to be `MyValueClass`, which has the `get_info()` method. Therefore, this call is type-safe.\n        *   If the type checker correctly infers `processed_item` as `MyValueClass` *before* the `isinstance` check, the check becomes redundant but harmless.\n\n6.  **Commented-out Code (Lines 75-77):**\n    The commented-out `AnotherValueClass` example correctly identifies a situation that *would* lead to a type error if uncommented. `AnotherValueClass` lacks the `update_value` method with the correct signature (specifically, `-> Self`), and thus does not satisfy the `ValueContainerProtocol`. Attempting to use it where `T_Valued` (bound by `ValueContainerProtocol`) is expected would correctly be flagged by a type checker as a `TypeVar` bound violation. However, since this code is commented out, it's not an active part of the analysis.\n\nIn conclusion, the active code meticulously adheres to Python's typing rules and PEPs. The \"disagreement points\" in the comments reflect common challenges in type checker implementation or interpretation, but the code itself is written in a type-safe manner according to the specification.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    },
    {
      "filename": "paramspec-decorator-with-classmethod-and-overload.py",
      "filepath": "generated_examples/2026-01-13_22-04-49/source_files/paramspec-decorator-with-classmethod-and-overload.py",
      "evaluations": {
        "mypy": [
          {
            "verdict": "INCORRECT",
            "reason": "Mypy completely missed the major type error where `custom_classmethod_decorator` (expecting a `Callable`) was applied to a `classmethod` object, which is not directly callable in the manner the decorator expects, resulting in a runtime `TypeError`.",
            "accuracy": "0/1 real issues caught",
            "analysis": "ISSUE 1: Incorrect decorator application order for `custom_classmethod_decorator` on an `@classmethod`.\n  - Line: 32\n  - Rule: When `@custom_classmethod_decorator` is applied above `@classmethod`, it means `custom_classmethod_decorator` is wrapping the `classmethod` object itself (i.e., `custom_classmethod_decorator(classmethod(func))`). The `custom_classmethod_decorator` is annotated to accept `func: Callable[P, R]`. However, a `classmethod` object is a descriptor and not directly callable in the way `Callable` implies (it first needs to be accessed via the class to produce a bound method). Attempting to call `func(*args, **kwargs)` where `func` is a `classmethod` object (as done in the `wrapper` function on line 18) will result in a runtime `TypeError: 'classmethod' object is not callable`.\n  - PEP Reference: PEP 484 (Callable type hints, Decorators section), Python's descriptor protocol.\n  - Should Error: YES. A type checker should identify that the argument provided to `custom_classmethod_decorator` (a `classmethod` object) does not satisfy its `Callable[P, R]` type constraint.\n\nRegarding the `reveal_type` statements:\n*   `reveal_type(single_res)`: Expected `ResourceManager`. This is correct because `C` in `def create_resource(cls: C, name: str) -> C` is specialized to `ResourceManager` when called on `ResourceManager`.\n*   `reveal_type(sub_res)`: Expected `SpecificResource`. This is correct because `C` is specialized to `SpecificResource` when called on `SpecificResource`.\n*   `reveal_type(multi_res)`: The matched overload is `def create_resource(cls: type, name: str, quantity: int) -> list[Any]: ...`. Therefore, a type checker should report `list[Any]`. While the implementation returns `list[str]`, type checkers typically adhere to the explicit return type specified in the matching overload signature. Reporting `list[Any]` is consistent with the declared type. (This is not a type safety violation, but rather a point of strict interpretation of `reveal_type` relative to overloads).\n*   `reveal_type(unknown_res)`: Expected `Any`. The matched overload is `def create_resource(cls: type, *args: Any, **kwargs: Any) -> Any: ...`. Therefore, a type checker should report `Any`. This is correct.",
            "method": "multi_step"
          },
          {
            "verdict": "CORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "pyrefly": [
          {
            "verdict": "PARTIAL",
            "reason": "The type checker missed the primary type compatibility issue identified in the analysis regarding the decorator stacking order, and also exhibited incorrect `reveal_type` inferences for `single_res` and `sub_res` (reporting `type[X]` instead of `X`); however, it correctly identified a separate runtime error where `self` was missing in an instance method definition.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "ISSUE 1: Incorrect decorator application order causing type incompatibility and a runtime error.\n  - Line: 28 (`@custom_classmethod_decorator`)\n  - Rule: Type compatibility for decorator arguments and function call. The `custom_classmethod_decorator` is defined to accept `func: Callable[P, R]`. However, due to the decorator stacking order `@custom_classmethod_decorator @classmethod`, the `custom_classmethod_decorator` is applied to the result of `@classmethod` (i.e., the `classmethod` descriptor object), not the original function. A `classmethod` descriptor object is not type-compatible with `Callable[P, R]` as its `__call__` method is not implemented to allow direct invocation like `func(*args, **kwargs)`. Attempting to call `func(*args, **kwargs)` inside the `wrapper` function of `custom_classmethod_decorator` when `func` is a `classmethod` descriptor will result in a `TypeError` at runtime.\n  - PEP Reference: PEP 484, \"Function decorators\" (for how decorators interact with type hints) and \"The `Callable` Type\" (for type-checking callable objects).\n  - Should Error: YES. A type checker should report that the `classmethod` descriptor object passed to `custom_classmethod_decorator` is incompatible with the expected `Callable[P, R]` type, or infer a runtime `TypeError` for the call.\n\n**Explanation of other potential points of disagreement:**\n\n*   **`reveal_type(single_res)`**: The expected type is `ResourceManager`. This is correct. The first overload `(cls: C, name: str) -> C` correctly infers `C` as `type[ResourceManager]` when called on `ResourceManager`, leading to an instance of `ResourceManager` as the return type.\n*   **`reveal_type(sub_res)`**: The expected type is `SpecificResource`. This is correct. Similar to `single_res`, `C` is correctly inferred as `type[SpecificResource]`, returning an instance of `SpecificResource`.\n*   **`reveal_type(multi_res)`**: The expected type is `list[Any]`. The second overload specifies `-> list[Any]`. While the implementation actually returns `list[str]`, `list[str]` is a subtype of `list[Any]`, making it a valid return. Type checkers should respect the overload's declared return type `list[Any]` for static analysis.\n*   **`reveal_type(unknown_res)`**: The expected type is `Any`. The third (catch-all) overload explicitly specifies `-> Any`. The implementation returns `None`, which is compatible with `Any`. This is correctly typed.\n\nNO OTHER ISSUES: Apart from the decorator application order, the rest of the code is type-safe according to the specified PEPs.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "zuban": [
          {
            "verdict": "INCORRECT",
            "reason": "The type checker failed to execute, reporting that it could not find the file, and therefore missed the single identified type safety violation.",
            "accuracy": "Caught 0/1 real issues",
            "analysis": "The provided code contains one type safety violation related to the incorrect application order of decorators.\n\nHere's a detailed analysis:\n\nISSUE 1: Incorrect decorator application order for `custom_classmethod_decorator` and `@classmethod`.\n  - Line: 29 (the line where `@custom_classmethod_decorator` is applied, implicitly indicating the incorrect stacking relative to `@classmethod`)\n  - Rule: Type incompatibility for function argument in decorator chain.\n    The `custom_classmethod_decorator` is defined to accept `func: Callable[P, R]`, meaning it expects a callable object as its argument.\n    The decorator stacking in the code is:\n    ```python\n    @custom_classmethod_decorator\n    @classmethod\n    def create_resource(cls: type, name: str, quantity: int) -> list[Any]: ...\n    ```\n    This translates conceptually to `create_resource = custom_classmethod_decorator(classmethod(create_resource_original_func))`.\n    The expression `classmethod(create_resource_original_func)` evaluates to a `classmethod` descriptor object during class definition. This `classmethod` descriptor object is *not* a `Callable` type that `custom_classmethod_decorator` expects for its `func` parameter. Descriptors are not directly callable with the `(P.args, P.kwargs)` signature in the same way a regular function or method is. This results in a type mismatch.\n    The `ParamSpec` `P` in `custom_classmethod_decorator` would also be unable to correctly resolve parameters from a `classmethod` descriptor, potentially leading to further type errors within the decorator's `wrapper` (e.g., when accessing `args[0]`).\n    For `custom_classmethod_decorator` to correctly wrap a class method, the `@classmethod` decorator should be applied *first* (or rather, *after* `custom_classmethod_decorator` in terms of code stacking, meaning `classmethod` wraps the result of `custom_classmethod_decorator`). This would look like:\n    ```python\n    @classmethod\n    @custom_classmethod_decorator\n    def create_resource(...): ...\n    ```\n    This would ensure `custom_classmethod_decorator` receives the original function (a `Callable`), returns a `wrapper` (also a `Callable`), and then `classmethod` correctly wraps this `wrapper`.\n  - PEP Reference: PEP 484, section \"Callable types\" and general type consistency rules.\n  - Should Error: YES\n\n**NO OTHER ISSUES:**\nThe `reveal_type` comments in the code indicate potential disagreements with type checker outputs (`Any` vs specific types). However, based on Python's typing rules and PEPs (especially how `TypeVar`s with `bound=type` are expected to resolve to instance types), the *expected* types in the `reveal_type` comments are correct according to the type hints provided in the code. If a type checker produces `Any` or a less specific type in those cases, it would be a limitation or bug in the type checker's inference, not a type safety violation in the source code itself. The provided type hints are self-consistent and correctly express the intended types.",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ],
        "ty": [
          {
            "verdict": "INCORRECT",
            "reason": "My analysis incorrectly stated \"NO ISSUES\", whereas the type checker correctly identified two legitimate type errors related to accessing `__name__` on a `classmethod` object (which is a descriptor and lacks `__name__`) and incorrect usage of `@overload` for classmethods.",
            "accuracy": "Caught 0/2 real issues",
            "analysis": "NO ISSUES: Code is type-safe",
            "method": "multi_step"
          },
          {
            "verdict": "INCORRECT",
            "reason": "Code is runtime-safe. ",
            "has_runtime_error": false,
            "method": "runtime"
          }
        ]
      }
    }
  ]
}