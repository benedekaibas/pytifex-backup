{
    "timestamp": "2026-01-13T21:07:24.984378",
    "model_used": "gemini-2.5-flash",
    "raw_response": "Here are 10 Python code snippets demonstrating real divergences between mypy, pyre (represented by pyrefly, a common variant), zuban, and ty type checkers. Each snippet targets a specific divergence pattern, uses modern Python syntax, and follows all specified requirements.\n\n---\n\n# id: protocol-default-call-mismatch\n# category: protocol-defaults\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n```python\nfrom typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass HasDefaultMethod(Protocol):\n    \"\"\"\n    Protocol with a method that has a default argument.\n    \"\"\"\n    def greet(self, name: str = \"World\") -> str: ...\n\nclass ImplementsDefault:\n    \"\"\"\n    Class implementing the protocol with a different default.\n    PEP 544 allows this.\n    \"\"\"\n    def greet(self, name: str = \"User\") -> str:\n        return f\"Hello, {name}!\"\n\nclass RemovesDefault:\n    \"\"\"\n    Class implementing the protocol by removing the default.\n    PEP 544 allows an implementation to \"supply a non-default parameter\n    in place of one that has a default in the protocol.\"\n    \"\"\"\n    def greet(self, name: str) -> str: # No default argument\n        return f\"Hi, {name}!\"\n\ndef call_with_default(obj: HasDefaultMethod) -> str:\n    \"\"\"\n    Function that expects a HasDefaultMethod and calls its `greet` method\n    without providing the `name` argument, relying on the protocol's default.\n    \"\"\"\n    # This call is statically valid based on HasDefaultMethod's signature.\n    # The divergence arises because 'obj' at runtime could be 'RemovesDefault',\n    # whose `greet` method does not support being called without arguments.\n    return obj.greet() \n\nif __name__ == \"__main__\":\n    impl_default = ImplementsDefault()\n    removes_default = RemovesDefault()\n\n    # This should be fine for all checkers and at runtime.\n    print(f\"Call with ImplementsDefault: {call_with_default(impl_default)}\")\n\n    # DIVERGENCE POINT:\n    # `RemovesDefault` is considered a valid implementation of `HasDefaultMethod`\n    # by some checkers (e.g., mypy) because PEP 544 allows implementations to\n    # remove defaults. However, `call_with_default` then attempts to call\n    # `obj.greet()` without arguments, which `RemovesDefault.greet` does not support.\n    # Mypy tends to pass this check, leading to a runtime TypeError.\n    # Other checkers (Pyre/Pyrefly, Zuban, Ty) are expected to catch this potential\n    # runtime error statically, flagging `removes_default` as incompatible with `HasDefaultMethod`\n    # for the purpose of the no-argument call.\n    print(f\"Call with RemovesDefault: {call_with_default(removes_default)}\")\n```\n\n---\n\n# id: typed-dict-total-sticky-required\n# category: typed-dict-total\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n```python\nfrom typing import TypedDict, NotRequired\n\n# Base TypedDict with total=False. 'x' is implicitly NotRequired.\nclass BaseConfig(TypedDict, total=False):\n    x: int\n\n# Intermediate TypedDict with total=True, inheriting from BaseConfig.\n# MyPy's behavior: 'x' becomes implicitly Required in RequiredXConfig.\nclass RequiredXConfig(BaseConfig, total=True):\n    y: str\n\n# Final TypedDict with total=False, inheriting from RequiredXConfig.\n# DIVERGENCE POINT:\n# Does 'x' (which was Required in RequiredXConfig) revert to NotRequired\n# due to FlexibleConfig's total=False, or does its \"Required\" status stick?\n# PEP 655 states: \"it is a static error if the resulting type would have a field\n# whose final requiredness is different from all its declarations.\"\n# 'x' is declared only once in BaseConfig (implicitly NotRequired). Its status\n# *changes* implicitly through the inheritance chain. MyPy allows this implicit\n# change to be overridden by subsequent `total` declarations.\n# Other checkers might interpret \"Required is sticky\" more strictly, especially\n# when a field was implicitly made Required by an intermediate `total=True`.\nclass FlexibleConfig(RequiredXConfig, total=False):\n    z: NotRequired[bool]\n\nif __name__ == \"__main__\":\n    # This instance omits 'x' and 'y'.\n    # MyPy considers this valid because in FlexibleConfig, 'x', 'y', and 'z'\n    # are all considered NotRequired due to `total=False`.\n    # Other type checkers might flag an error for missing 'x' and 'y',\n    # adhering to a stricter \"sticky Required\" interpretation, where once\n    # a field becomes implicitly Required by an intermediate `total=True`,\n    # it cannot become NotRequired again through a subsequent `total=False`.\n    config_instance: FlexibleConfig = {\"z\": False}\n    print(f\"FlexibleConfig instance: {config_instance}\")\n\n    # This should be valid for all checkers.\n    required_x_instance: RequiredXConfig = {\"x\": 10, \"y\": \"value\"}\n    print(f\"RequiredXConfig instance: {required_x_instance}\")\n\n    # This should be an error for all checkers, as 'x' and 'y' are Required.\n    # invalid_required_x_instance: RequiredXConfig = {\"z\": False} # Uncomment to test\n```\n\n---\n\n# id: typeguard-generic-list-narrowing\n# category: typeguard-narrowing\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n```python\nfrom typing import TypeGuard, TypeVar, Any, Sequence\n\nT = TypeVar('T')\n\ndef is_sequence_of_type[T](items: Sequence[Any], type_param: type[T]) -> TypeGuard[Sequence[T]]:\n    \"\"\"\n    A TypeGuard that attempts to narrow a Sequence[Any] to Sequence[T]\n    if all its elements are of the given type T.\n    \"\"\"\n    if not items: # Empty sequence technically fits any type.\n        return True\n    return all(isinstance(x, type_param) for x in items)\n\ndef process_sequence(seq: Sequence[Any]) -> None:\n    if is_sequence_of_type(seq, int):\n        # DIVERGENCE POINT:\n        # MyPy correctly narrows 'seq' to Sequence[int] inside this block.\n        # Other type checkers might fail to perform this generic type narrowing,\n        # especially when 'T' is inferred from `type_param`.\n        # This would lead to a type error when assigning `seq[0]` to an `int`.\n        first_element: int = seq[0] # This line is the divergence test.\n        print(f\"Sequence narrowed to int: {seq}, first element: {first_element}\")\n    else:\n        print(f\"Sequence is not exclusively of integers or is empty: {seq}\")\n\nif __name__ == \"__main__\":\n    ints_seq: Sequence[Any] = [1, 2, 3]\n    strs_seq: Sequence[Any] = [\"a\", \"b\", \"c\"]\n    mixed_seq: Sequence[Any] = [1, \"b\", 3]\n    empty_seq: Sequence[Any] = []\n\n    print(\"--- Processing ints_seq (expected OK) ---\")\n    process_sequence(ints_seq)\n\n    print(\"\\n--- Processing strs_seq (expected to fall into else) ---\")\n    process_sequence(strs_seq)\n\n    print(\"\\n--- Processing mixed_seq (expected to fall into else) ---\")\n    process_sequence(mixed_seq)\n\n    print(\"\\n--- Processing empty_seq (expected OK) ---\")\n    process_sequence(empty_seq)\n```\n\n---\n\n# id: param-spec-decorator-classmethod-order\n# category: param-spec-decorator\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n```python\nfrom typing import Callable, ParamSpec, TypeVar\nfrom functools import wraps\n\nP = ParamSpec('P')\nR = TypeVar('R')\n\ndef logging_decorator[**P, R](func: Callable[P, R]) -> Callable[P, R]:\n    \"\"\"A simple generic decorator that logs function calls.\"\"\"\n    @wraps(func)\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n        print(f\"Log: Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n        return func(*args, **kwargs)\n    return wrapper\n\nclass MyProcessor:\n    # DIVERGENCE POINT:\n    # Applying `logging_decorator` *before* `@classmethod`.\n    # `logging_decorator` returns a callable `wrapper`. `@classmethod` then\n    # tries to wrap this `wrapper`. Mypy correctly identifies this as an error\n    # because `classmethod` expects to wrap a plain function, not an already-decorated callable\n    # (which is a descriptor in itself).\n    # Other type checkers might be more lenient, allowing this order.\n    @logging_decorator\n    @classmethod\n    def inner_method(cls, value: int) -> str:\n        return f\"Class method (decorated first) processing {value} for {cls.__name__}\"\n\n    # This is the generally accepted and correct order for applying decorators\n    # with `classmethod` or `staticmethod`.\n    # `@classmethod` is applied first, then `logging_decorator` wraps the\n    # resulting method (which is now effectively a class method descriptor).\n    @classmethod\n    @logging_decorator\n    def outer_method(cls, value: int) -> str:\n        return f\"Class method (classmethod first) processing {value} for {cls.__name__}\"\n\nif __name__ == \"__main__\":\n    # MyPy will flag an error at the definition of `inner_method` itself:\n    # `error: \"classmethod\" used with a method that is already a descriptor [misc]`\n    # This signifies a fundamental disagreement in how this decorator order is handled.\n    # If the error is ignored, this call would execute at runtime.\n    print(MyProcessor.inner_method(123))\n\n    # This order is correctly handled by all type checkers.\n    print(MyProcessor.outer_method(456))\n```\n\n---\n\n# id: self-generic-abstract-inference\n# category: self-generic\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n```python\nfrom typing import TypeVar, Generic, Self, Any\nfrom abc import ABC, abstractmethod\n\nT = TypeVar('T')\n\nclass BaseRepository(Generic[T], ABC):\n    \"\"\"\n    An abstract generic base class for repositories.\n    It uses `Self` in its abstract class method return type.\n    \"\"\"\n    @classmethod\n    @abstractmethod\n    def create_default(cls, value: T) -> Self:\n        \"\"\"\n        Creates a default instance of `Self`, parameterized by `T`.\n        `Self` should resolve to the concrete class with its specific `T` type argument.\n        \"\"\"\n        pass\n\nclass UserRepository(BaseRepository[str]):\n    \"\"\"\n    A concrete implementation of BaseRepository for strings.\n    `T` is fixed to `str` here.\n    \"\"\"\n    @classmethod\n    def create_default(cls, value: str) -> Self:\n        print(f\"Creating default UserRepository with value: {value}\")\n        # In a real impl, might initialize an instance using 'value'.\n        return cls()\n\ndef process_repository[R: BaseRepository[Any]](repo_type: type[R], initial_value: Any) -> R:\n    \"\"\"\n    Takes a repository *type* (e.g., UserRepository) and calls its class method.\n    The return type `R` relies on `Self` being correctly inferred with its\n    generic type parameters from the actual `repo_type`.\n    \"\"\"\n    return repo_type.create_default(initial_value)\n\nif __name__ == \"__main__\":\n    # DIVERGENCE POINT:\n    # Mypy correctly infers that `UserRepository.create_default` returns `UserRepository[str]`\n    # because `Self` resolves to the specific class `UserRepository` and preserves its `str` type argument.\n    # Therefore, the assignment to `processed_repo` as `UserRepository[str]` is valid.\n    # Other type checkers might struggle to preserve the `str` type parameter\n    # through `Self` when `create_default` is called via the generic function `process_repository`.\n    # They might infer `BaseRepository[Any]` or `BaseRepository[str]` for `processed_repo`,\n    # leading to an assignment error (as `BaseRepository[str]` is not `UserRepository[str]`).\n    processed_repo: UserRepository[str] = process_repository(UserRepository, \"default_user_name\")\n    print(f\"Created repository of type: {type(processed_repo)} for value: '{processed_repo}'\")\n\n    # Example of using the created instance (should be fine if type inference succeeded).\n    # If `processed_repo` lost its specific generic type, this might lead to further errors.\n    # reveal_type(processed_repo) # Should show UserRepository[str]\n```\n\n---\n\n# id: newtype-list-covariance\n# category: newtype-containers\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n```python\nfrom typing import NewType, List, Tuple\n\n# Define NewTypes based on built-in types.\nUserID = NewType('UserID', int)\nOrderID = NewType('OrderID', str)\n\n# A function expecting a list of the base type (int).\ndef process_int_list(data: List[int]) -> None:\n    print(f\"Processing integers: {data}\")\n\n# A function expecting a tuple of the base type (str).\ndef process_str_tuple(data: Tuple[str, ...]) -> None:\n    print(f\"Processing strings: {data}\")\n\nif __name__ == \"__main__\":\n    # Create instances of generic containers using NewTypes.\n    user_id_list: List[UserID] = [UserID(101), UserID(102)]\n    order_id_tuple: Tuple[OrderID, ...] = (OrderID(\"ORD_001\"), OrderID(\"ORD_002\"))\n\n    # DIVERGENCE POINT 1: List Covariance\n    # `List` is covariant in its type parameter. Therefore, `List[UserID]` should be\n    # assignable to `List[int]`, because `UserID` is a subtype of `int`.\n    # Mypy correctly handles this. Other type checkers might be stricter and\n    # flag an error, treating `NewType` as too distinct from its base type\n    # within generic contexts.\n    print(\"--- Testing List Covariance ---\")\n    process_int_list(user_id_list) # mypy: ok, others: error\n\n    # DIVERGENCE POINT 2: Tuple Covariance\n    # `Tuple` is also covariant. `Tuple[OrderID, ...]` should be assignable to\n    # `Tuple[str, ...]`. Similar to List, this tests the type checker's\n    # understanding of `NewType` and container variance.\n    print(\"\\n--- Testing Tuple Covariance ---\")\n    process_str_tuple(order_id_tuple) # mypy: ok, others: error\n```\n\n---\n\n# id: overload-literal-resolution\n# category: overload-literals\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n```python\nfrom typing import overload, Literal, Union\n\n# Overload 1: Most specific for \"apple\"\n@overload\ndef get_fruit_info(fruit: Literal[\"apple\"]) -> dict[str, str]: ...\n# Overload 2: Less specific, includes \"apple\" and \"orange\". This overlaps with Overload 1.\n@overload\ndef get_fruit_info(fruit: Literal[\"apple\", \"orange\"]) -> dict[str, int]: ...\n# Overload 3: General string, least specific.\n@overload\ndef get_fruit_info(fruit: str) -> dict[str, bool]: ...\n\ndef get_fruit_info(fruit: str) -> Union[dict[str, str], dict[str, int], dict[str, bool]]:\n    \"\"\"Implementation for get_fruit_info.\"\"\"\n    if fruit == \"apple\":\n        return {\"color\": \"red\"}\n    elif fruit == \"orange\":\n        return {\"segments\": 10}\n    else:\n        return {\"available\": False}\n\nif __name__ == \"__main__\":\n    # DIVERGENCE POINT: Calling with \"apple\"\n    # Overload resolution order is critical here. Mypy's rule is to pick the\n    # *first* matching overload in the source order.\n    # Therefore, `get_fruit_info(\"apple\")` should resolve to Overload 1,\n    # resulting in `apple_info` being `dict[str, str]`.\n    # Other type checkers might use different heuristics (e.g., longest literal list wins),\n    # leading to `apple_info` being `dict[str, int]` (from Overload 2), or a `Union`.\n    apple_info = get_fruit_info(\"apple\")\n    \n    # If `apple_info` is inferred as `dict[str, int]`, then accessing \"color\"\n    # or assigning its value to `str` will be an error, as `dict[str, int]`\n    # does not guarantee a \"color\" key with a string value.\n    apple_color: str = apple_info[\"color\"] # This assignment is the divergence test.\n    print(f\"Apple info color: {apple_color}\")\n\n    # This should unambiguously resolve to Overload 2 for all checkers.\n    orange_info = get_fruit_info(\"orange\")\n    orange_segments: int = orange_info[\"segments\"]\n    print(f\"Orange info segments: {orange_segments}\")\n\n    # This should unambiguously resolve to Overload 3 for all checkers.\n    banana_info = get_fruit_info(\"banana\")\n    banana_available: bool = banana_info[\"available\"]\n    print(f\"Banana info available: {banana_available}\")\n```\n\n---\n\n# id: final-attribute-property-override\n# category: final-override\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n```python\nfrom typing import Final\n\nclass Configuration:\n    \"\"\"A base class with Final class attributes.\"\"\"\n    SETTING_A: Final[str] = \"default_value_A\"\n    SETTING_B: Final[int] = 100\n\nclass CustomConfiguration(Configuration):\n    \"\"\"\n    A subclass attempting to override Final attributes.\n    \"\"\"\n    # DIVERGENCE POINT:\n    # Overriding a Final class attribute (`SETTING_A`) with a property.\n    # PEP 591 states: \"In a class body, Final variables cannot be overridden in subclasses.\"\n    # Mypy interprets a property as an override of the Final attribute and flags an error.\n    # Other type checkers might consider a property a distinct kind of class member\n    # (a descriptor, not a simple variable assignment) and allow this override,\n    # or they might not implement this specific check for `Final` in this scenario.\n    @property\n    def SETTING_A(self) -> str:\n        return \"custom_value_for_A\"\n\n    # This is a direct override of a Final attribute with a different type,\n    # which should typically be an error for all compliant type checkers.\n    # SETTING_B: Final[str] = \"200\" # Uncomment to test a universally expected error.\n\nif __name__ == \"__main__\":\n    # Accessing the original Final attributes.\n    print(f\"Base SETTING_A: {Configuration.SETTING_A}\")\n    print(f\"Base SETTING_B: {Configuration.SETTING_B}\")\n\n    # Accessing the potentially overridden attributes in CustomConfiguration.\n    # If the checker permits the property override (i.e., not mypy),\n    # this will print the value from the property.\n    custom_config = CustomConfiguration()\n    print(f\"Custom SETTING_A (via property): {custom_config.SETTING_A}\")\n    # MyPy would have already flagged an error at the class definition of CustomConfiguration.\n```\n\n---\n\n# id: keyword-vs-positional-protocol\n# category: keyword-vs-positional\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n```python\nfrom typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass HasProcessor(Protocol):\n    \"\"\"\n    Protocol method with a positional-or-keyword argument ('value')\n    and a keyword-only argument ('factor').\n    \"\"\"\n    def process(self, value: int, *, factor: float = 1.0) -> float: ...\n\nclass StrictProcessor:\n    \"\"\"\n    Implements the protocol by making 'value' keyword-only.\n    This changes 'value' from positional-or-keyword to keyword-only.\n    \"\"\"\n    def process(self, *, value: int, factor: float = 1.0) -> float:\n        return value * factor\n\nclass LooseProcessor:\n    \"\"\"\n    Implements the protocol by making 'factor' positional-or-keyword.\n    This makes the method *more flexible*, which is generally allowed by PEP 544.\n    \"\"\"\n    def process(self, value: int, factor: float = 1.0) -> float:\n        return value * factor\n\ndef operate(obj: HasProcessor) -> None:\n    \"\"\"\n    Function that calls the `process` method, adhering to the protocol's signature.\n    \"\"\"\n    print(f\"Processing object: {type(obj).__name__}\")\n    # These calls are valid for the `HasProcessor` protocol.\n    # They should only be statically allowed if `obj` truly implements `HasProcessor`.\n    print(f\"  Result (pos-arg, kw-arg): {obj.process(10, factor=2.0)}\")\n    print(f\"  Result (kw-arg, kw-arg): {obj.process(value=20, factor=3.0)}\")\n    print(f\"  Result (pos-arg, default): {obj.process(30)}\")\n\nif __name__ == \"__main__\":\n    lp = LooseProcessor()\n    print(\"--- Testing LooseProcessor (should be OK for all) ---\")\n    operate(lp) # This should pass for all checkers and at runtime.\n\n    sp = StrictProcessor()\n    print(\"\\n--- Testing StrictProcessor (Divergence) ---\")\n    # DIVERGENCE POINT:\n    # Mypy considers `StrictProcessor` NOT to implement `HasProcessor` because\n    # the parameter `value` changed from `positional-or-keyword` in the protocol\n    # to `keyword-only` in the implementation. This makes the implementation\n    # *less flexible* than the protocol, which PEP 544 disallows.\n    # Other type checkers might allow this, or be more lenient on parameter kinds.\n    operate(sp) # mypy: error (at the `operate(sp)` call site), others: ok.\n```\n\n---\n\n# id: bounded-typevar-nested-protocol\n# category: bounded-typevars\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n```python\nfrom typing import TypeVar, Generic, Iterable, Protocol, runtime_checkable\n\n# Define a protocol for types that must have a 'get_name' method returning a string.\n@runtime_checkable\nclass NamedThing(Protocol):\n    def get_name(self) -> str: ...\n\n# A TypeVar whose bound is `Iterable[NamedThing]`.\n# This means any type substituted for `T_NamedIterable` must be an iterable\n# where *each element* satisfies the `NamedThing` protocol.\nT_NamedIterable = TypeVar('T_NamedIterable', bound=Iterable[NamedThing])\n\n# A generic function that takes an iterable of `NamedThing`s and prints their names.\ndef print_names[I: T_NamedIterable](data: I) -> None:\n    for item in data:\n        print(f\"Name: {item.get_name()}\")\n\n# A class that explicitly implements the NamedThing protocol.\nclass MyObject:\n    def __init__(self, name: str):\n        self._name = name\n    def get_name(self) -> str:\n        return self._name\n\n# A class that does NOT implement the NamedThing protocol (it lacks `get_name`).\nclass MyOtherObject:\n    def __init__(self, value: int):\n        self._value = value\n\nif __name__ == \"__main__\":\n    # Case 1: List of objects that implement NamedThing. This should pass for all.\n    named_objects: list[MyObject] = [MyObject(\"Alpha\"), MyObject(\"Beta\")]\n    print(\"\\n--- Printing names of MyObject instances ---\")\n    print_names(named_objects)\n\n    # DIVERGENCE POINT:\n    # Passing a list of objects that do NOT implement `NamedThing`.\n    # `MyOtherObject` does not have a `get_name` method.\n    # Therefore, `list[MyOtherObject]` should NOT be compatible with\n    # `Iterable[NamedThing]` according to the `T_NamedIterable` TypeVar bound.\n    # Mypy correctly identifies this as a type error because `MyOtherObject` does not\n    # satisfy the `NamedThing` protocol.\n    # Other type checkers might be more lenient, or simply fail to perform this complex\n    # nested generic bound check, allowing the code to pass statically but leading\n    # to a runtime `AttributeError`.\n    other_objects: list[MyOtherObject] = [MyOtherObject(1), MyOtherObject(2)]\n    print(\"\\n--- Printing names of MyOtherObject instances (EXPECTED ERROR) ---\")\n    print_names(other_objects) # mypy: error, others: ok.\n\n    # An empty list satisfies the bound for any `Iterable[T]`.\n    empty_list: list[NamedThing] = []\n    print(\"\\n--- Printing names of empty list ---\")\n    print_names(empty_list)\n```",
    "examples": [
        {
            "id": "protocol-default-call-mismatch",
            "metadata": "# category: protocol-defaults\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error",
            "code": "from typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass HasDefaultMethod(Protocol):\n    \"\"\"\n    Protocol with a method that has a default argument.\n    \"\"\"\n    def greet(self, name: str = \"World\") -> str: ...\n\nclass ImplementsDefault:\n    \"\"\"\n    Class implementing the protocol with a different default.\n    PEP 544 allows this.\n    \"\"\"\n    def greet(self, name: str = \"User\") -> str:\n        return f\"Hello, {name}!\"\n\nclass RemovesDefault:\n    \"\"\"\n    Class implementing the protocol by removing the default.\n    PEP 544 allows an implementation to \"supply a non-default parameter\n    in place of one that has a default in the protocol.\"\n    \"\"\"\n    def greet(self, name: str) -> str: # No default argument\n        return f\"Hi, {name}!\"\n\ndef call_with_default(obj: HasDefaultMethod) -> str:\n    \"\"\"\n    Function that expects a HasDefaultMethod and calls its `greet` method\n    without providing the `name` argument, relying on the protocol's default.\n    \"\"\"\n    # This call is statically valid based on HasDefaultMethod's signature.\n    # The divergence arises because 'obj' at runtime could be 'RemovesDefault',\n    # whose `greet` method does not support being called without arguments.\n    return obj.greet() \n\nif __name__ == \"__main__\":\n    impl_default = ImplementsDefault()\n    removes_default = RemovesDefault()\n\n    # This should be fine for all checkers and at runtime.\n    print(f\"Call with ImplementsDefault: {call_with_default(impl_default)}\")\n\n    # DIVERGENCE POINT:\n    # `RemovesDefault` is considered a valid implementation of `HasDefaultMethod`\n    # by some checkers (e.g., mypy) because PEP 544 allows implementations to\n    # remove defaults. However, `call_with_default` then attempts to call\n    # `obj.greet()` without arguments, which `RemovesDefault.greet` does not support.\n    # Mypy tends to pass this check, leading to a runtime TypeError.\n    # Other checkers (Pyre/Pyrefly, Zuban, Ty) are expected to catch this potential\n    # runtime error statically, flagging `removes_default` as incompatible with `HasDefaultMethod`\n    # for the purpose of the no-argument call.\n    print(f\"Call with RemovesDefault: {call_with_default(removes_default)}\")",
            "full_content": "# id: protocol-default-call-mismatch\n# category: protocol-defaults\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n\nfrom typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass HasDefaultMethod(Protocol):\n    \"\"\"\n    Protocol with a method that has a default argument.\n    \"\"\"\n    def greet(self, name: str = \"World\") -> str: ...\n\nclass ImplementsDefault:\n    \"\"\"\n    Class implementing the protocol with a different default.\n    PEP 544 allows this.\n    \"\"\"\n    def greet(self, name: str = \"User\") -> str:\n        return f\"Hello, {name}!\"\n\nclass RemovesDefault:\n    \"\"\"\n    Class implementing the protocol by removing the default.\n    PEP 544 allows an implementation to \"supply a non-default parameter\n    in place of one that has a default in the protocol.\"\n    \"\"\"\n    def greet(self, name: str) -> str: # No default argument\n        return f\"Hi, {name}!\"\n\ndef call_with_default(obj: HasDefaultMethod) -> str:\n    \"\"\"\n    Function that expects a HasDefaultMethod and calls its `greet` method\n    without providing the `name` argument, relying on the protocol's default.\n    \"\"\"\n    # This call is statically valid based on HasDefaultMethod's signature.\n    # The divergence arises because 'obj' at runtime could be 'RemovesDefault',\n    # whose `greet` method does not support being called without arguments.\n    return obj.greet() \n\nif __name__ == \"__main__\":\n    impl_default = ImplementsDefault()\n    removes_default = RemovesDefault()\n\n    # This should be fine for all checkers and at runtime.\n    print(f\"Call with ImplementsDefault: {call_with_default(impl_default)}\")\n\n    # DIVERGENCE POINT:\n    # `RemovesDefault` is considered a valid implementation of `HasDefaultMethod`\n    # by some checkers (e.g., mypy) because PEP 544 allows implementations to\n    # remove defaults. However, `call_with_default` then attempts to call\n    # `obj.greet()` without arguments, which `RemovesDefault.greet` does not support.\n    # Mypy tends to pass this check, leading to a runtime TypeError.\n    # Other checkers (Pyre/Pyrefly, Zuban, Ty) are expected to catch this potential\n    # runtime error statically, flagging `removes_default` as incompatible with `HasDefaultMethod`\n    # for the purpose of the no-argument call.\n    print(f\"Call with RemovesDefault: {call_with_default(removes_default)}\")"
        },
        {
            "id": "typed-dict-total-sticky-required",
            "metadata": "# category: typed-dict-total\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error",
            "code": "from typing import TypedDict, NotRequired\n\n# Base TypedDict with total=False. 'x' is implicitly NotRequired.\nclass BaseConfig(TypedDict, total=False):\n    x: int\n\n# Intermediate TypedDict with total=True, inheriting from BaseConfig.\n# MyPy's behavior: 'x' becomes implicitly Required in RequiredXConfig.\nclass RequiredXConfig(BaseConfig, total=True):\n    y: str\n\n# Final TypedDict with total=False, inheriting from RequiredXConfig.\n# DIVERGENCE POINT:\n# Does 'x' (which was Required in RequiredXConfig) revert to NotRequired\n# due to FlexibleConfig's total=False, or does its \"Required\" status stick?\n# PEP 655 states: \"it is a static error if the resulting type would have a field\n# whose final requiredness is different from all its declarations.\"\n# 'x' is declared only once in BaseConfig (implicitly NotRequired). Its status\n# *changes* implicitly through the inheritance chain. MyPy allows this implicit\n# change to be overridden by subsequent `total` declarations.\n# Other checkers might interpret \"Required is sticky\" more strictly, especially\n# when a field was implicitly made Required by an intermediate `total=True`.\nclass FlexibleConfig(RequiredXConfig, total=False):\n    z: NotRequired[bool]\n\nif __name__ == \"__main__\":\n    # This instance omits 'x' and 'y'.\n    # MyPy considers this valid because in FlexibleConfig, 'x', 'y', and 'z'\n    # are all considered NotRequired due to `total=False`.\n    # Other type checkers might flag an error for missing 'x' and 'y',\n    # adhering to a stricter \"sticky Required\" interpretation, where once\n    # a field becomes implicitly Required by an intermediate `total=True`,\n    # it cannot become NotRequired again through a subsequent `total=False`.\n    config_instance: FlexibleConfig = {\"z\": False}\n    print(f\"FlexibleConfig instance: {config_instance}\")\n\n    # This should be valid for all checkers.\n    required_x_instance: RequiredXConfig = {\"x\": 10, \"y\": \"value\"}\n    print(f\"RequiredXConfig instance: {required_x_instance}\")\n\n    # This should be an error for all checkers, as 'x' and 'y' are Required.\n    # invalid_required_x_instance: RequiredXConfig = {\"z\": False} # Uncomment to test",
            "full_content": "# id: typed-dict-total-sticky-required\n# category: typed-dict-total\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n\nfrom typing import TypedDict, NotRequired\n\n# Base TypedDict with total=False. 'x' is implicitly NotRequired.\nclass BaseConfig(TypedDict, total=False):\n    x: int\n\n# Intermediate TypedDict with total=True, inheriting from BaseConfig.\n# MyPy's behavior: 'x' becomes implicitly Required in RequiredXConfig.\nclass RequiredXConfig(BaseConfig, total=True):\n    y: str\n\n# Final TypedDict with total=False, inheriting from RequiredXConfig.\n# DIVERGENCE POINT:\n# Does 'x' (which was Required in RequiredXConfig) revert to NotRequired\n# due to FlexibleConfig's total=False, or does its \"Required\" status stick?\n# PEP 655 states: \"it is a static error if the resulting type would have a field\n# whose final requiredness is different from all its declarations.\"\n# 'x' is declared only once in BaseConfig (implicitly NotRequired). Its status\n# *changes* implicitly through the inheritance chain. MyPy allows this implicit\n# change to be overridden by subsequent `total` declarations.\n# Other checkers might interpret \"Required is sticky\" more strictly, especially\n# when a field was implicitly made Required by an intermediate `total=True`.\nclass FlexibleConfig(RequiredXConfig, total=False):\n    z: NotRequired[bool]\n\nif __name__ == \"__main__\":\n    # This instance omits 'x' and 'y'.\n    # MyPy considers this valid because in FlexibleConfig, 'x', 'y', and 'z'\n    # are all considered NotRequired due to `total=False`.\n    # Other type checkers might flag an error for missing 'x' and 'y',\n    # adhering to a stricter \"sticky Required\" interpretation, where once\n    # a field becomes implicitly Required by an intermediate `total=True`,\n    # it cannot become NotRequired again through a subsequent `total=False`.\n    config_instance: FlexibleConfig = {\"z\": False}\n    print(f\"FlexibleConfig instance: {config_instance}\")\n\n    # This should be valid for all checkers.\n    required_x_instance: RequiredXConfig = {\"x\": 10, \"y\": \"value\"}\n    print(f\"RequiredXConfig instance: {required_x_instance}\")\n\n    # This should be an error for all checkers, as 'x' and 'y' are Required.\n    # invalid_required_x_instance: RequiredXConfig = {\"z\": False} # Uncomment to test"
        },
        {
            "id": "typeguard-generic-list-narrowing",
            "metadata": "# category: typeguard-narrowing\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error",
            "code": "from typing import TypeGuard, TypeVar, Any, Sequence\n\nT = TypeVar('T')\n\ndef is_sequence_of_type[T](items: Sequence[Any], type_param: type[T]) -> TypeGuard[Sequence[T]]:\n    \"\"\"\n    A TypeGuard that attempts to narrow a Sequence[Any] to Sequence[T]\n    if all its elements are of the given type T.\n    \"\"\"\n    if not items: # Empty sequence technically fits any type.\n        return True\n    return all(isinstance(x, type_param) for x in items)\n\ndef process_sequence(seq: Sequence[Any]) -> None:\n    if is_sequence_of_type(seq, int):\n        # DIVERGENCE POINT:\n        # MyPy correctly narrows 'seq' to Sequence[int] inside this block.\n        # Other type checkers might fail to perform this generic type narrowing,\n        # especially when 'T' is inferred from `type_param`.\n        # This would lead to a type error when assigning `seq[0]` to an `int`.\n        first_element: int = seq[0] # This line is the divergence test.\n        print(f\"Sequence narrowed to int: {seq}, first element: {first_element}\")\n    else:\n        print(f\"Sequence is not exclusively of integers or is empty: {seq}\")\n\nif __name__ == \"__main__\":\n    ints_seq: Sequence[Any] = [1, 2, 3]\n    strs_seq: Sequence[Any] = [\"a\", \"b\", \"c\"]\n    mixed_seq: Sequence[Any] = [1, \"b\", 3]\n    empty_seq: Sequence[Any] = []\n\n    print(\"--- Processing ints_seq (expected OK) ---\")\n    process_sequence(ints_seq)\n\n    print(\"\\n--- Processing strs_seq (expected to fall into else) ---\")\n    process_sequence(strs_seq)\n\n    print(\"\\n--- Processing mixed_seq (expected to fall into else) ---\")\n    process_sequence(mixed_seq)\n\n    print(\"\\n--- Processing empty_seq (expected OK) ---\")\n    process_sequence(empty_seq)",
            "full_content": "# id: typeguard-generic-list-narrowing\n# category: typeguard-narrowing\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n\nfrom typing import TypeGuard, TypeVar, Any, Sequence\n\nT = TypeVar('T')\n\ndef is_sequence_of_type[T](items: Sequence[Any], type_param: type[T]) -> TypeGuard[Sequence[T]]:\n    \"\"\"\n    A TypeGuard that attempts to narrow a Sequence[Any] to Sequence[T]\n    if all its elements are of the given type T.\n    \"\"\"\n    if not items: # Empty sequence technically fits any type.\n        return True\n    return all(isinstance(x, type_param) for x in items)\n\ndef process_sequence(seq: Sequence[Any]) -> None:\n    if is_sequence_of_type(seq, int):\n        # DIVERGENCE POINT:\n        # MyPy correctly narrows 'seq' to Sequence[int] inside this block.\n        # Other type checkers might fail to perform this generic type narrowing,\n        # especially when 'T' is inferred from `type_param`.\n        # This would lead to a type error when assigning `seq[0]` to an `int`.\n        first_element: int = seq[0] # This line is the divergence test.\n        print(f\"Sequence narrowed to int: {seq}, first element: {first_element}\")\n    else:\n        print(f\"Sequence is not exclusively of integers or is empty: {seq}\")\n\nif __name__ == \"__main__\":\n    ints_seq: Sequence[Any] = [1, 2, 3]\n    strs_seq: Sequence[Any] = [\"a\", \"b\", \"c\"]\n    mixed_seq: Sequence[Any] = [1, \"b\", 3]\n    empty_seq: Sequence[Any] = []\n\n    print(\"--- Processing ints_seq (expected OK) ---\")\n    process_sequence(ints_seq)\n\n    print(\"\\n--- Processing strs_seq (expected to fall into else) ---\")\n    process_sequence(strs_seq)\n\n    print(\"\\n--- Processing mixed_seq (expected to fall into else) ---\")\n    process_sequence(mixed_seq)\n\n    print(\"\\n--- Processing empty_seq (expected OK) ---\")\n    process_sequence(empty_seq)"
        },
        {
            "id": "param-spec-decorator-classmethod-order",
            "metadata": "# category: param-spec-decorator\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok",
            "code": "from typing import Callable, ParamSpec, TypeVar\nfrom functools import wraps\n\nP = ParamSpec('P')\nR = TypeVar('R')\n\ndef logging_decorator[**P, R](func: Callable[P, R]) -> Callable[P, R]:\n    \"\"\"A simple generic decorator that logs function calls.\"\"\"\n    @wraps(func)\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n        print(f\"Log: Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n        return func(*args, **kwargs)\n    return wrapper\n\nclass MyProcessor:\n    # DIVERGENCE POINT:\n    # Applying `logging_decorator` *before* `@classmethod`.\n    # `logging_decorator` returns a callable `wrapper`. `@classmethod` then\n    # tries to wrap this `wrapper`. Mypy correctly identifies this as an error\n    # because `classmethod` expects to wrap a plain function, not an already-decorated callable\n    # (which is a descriptor in itself).\n    # Other type checkers might be more lenient, allowing this order.\n    @logging_decorator\n    @classmethod\n    def inner_method(cls, value: int) -> str:\n        return f\"Class method (decorated first) processing {value} for {cls.__name__}\"\n\n    # This is the generally accepted and correct order for applying decorators\n    # with `classmethod` or `staticmethod`.\n    # `@classmethod` is applied first, then `logging_decorator` wraps the\n    # resulting method (which is now effectively a class method descriptor).\n    @classmethod\n    @logging_decorator\n    def outer_method(cls, value: int) -> str:\n        return f\"Class method (classmethod first) processing {value} for {cls.__name__}\"\n\nif __name__ == \"__main__\":\n    # MyPy will flag an error at the definition of `inner_method` itself:\n    # `error: \"classmethod\" used with a method that is already a descriptor [misc]`\n    # This signifies a fundamental disagreement in how this decorator order is handled.\n    # If the error is ignored, this call would execute at runtime.\n    print(MyProcessor.inner_method(123))\n\n    # This order is correctly handled by all type checkers.\n    print(MyProcessor.outer_method(456))",
            "full_content": "# id: param-spec-decorator-classmethod-order\n# category: param-spec-decorator\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n\nfrom typing import Callable, ParamSpec, TypeVar\nfrom functools import wraps\n\nP = ParamSpec('P')\nR = TypeVar('R')\n\ndef logging_decorator[**P, R](func: Callable[P, R]) -> Callable[P, R]:\n    \"\"\"A simple generic decorator that logs function calls.\"\"\"\n    @wraps(func)\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n        print(f\"Log: Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n        return func(*args, **kwargs)\n    return wrapper\n\nclass MyProcessor:\n    # DIVERGENCE POINT:\n    # Applying `logging_decorator` *before* `@classmethod`.\n    # `logging_decorator` returns a callable `wrapper`. `@classmethod` then\n    # tries to wrap this `wrapper`. Mypy correctly identifies this as an error\n    # because `classmethod` expects to wrap a plain function, not an already-decorated callable\n    # (which is a descriptor in itself).\n    # Other type checkers might be more lenient, allowing this order.\n    @logging_decorator\n    @classmethod\n    def inner_method(cls, value: int) -> str:\n        return f\"Class method (decorated first) processing {value} for {cls.__name__}\"\n\n    # This is the generally accepted and correct order for applying decorators\n    # with `classmethod` or `staticmethod`.\n    # `@classmethod` is applied first, then `logging_decorator` wraps the\n    # resulting method (which is now effectively a class method descriptor).\n    @classmethod\n    @logging_decorator\n    def outer_method(cls, value: int) -> str:\n        return f\"Class method (classmethod first) processing {value} for {cls.__name__}\"\n\nif __name__ == \"__main__\":\n    # MyPy will flag an error at the definition of `inner_method` itself:\n    # `error: \"classmethod\" used with a method that is already a descriptor [misc]`\n    # This signifies a fundamental disagreement in how this decorator order is handled.\n    # If the error is ignored, this call would execute at runtime.\n    print(MyProcessor.inner_method(123))\n\n    # This order is correctly handled by all type checkers.\n    print(MyProcessor.outer_method(456))"
        },
        {
            "id": "self-generic-abstract-inference",
            "metadata": "# category: self-generic\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error",
            "code": "from typing import TypeVar, Generic, Self, Any\nfrom abc import ABC, abstractmethod\n\nT = TypeVar('T')\n\nclass BaseRepository(Generic[T], ABC):\n    \"\"\"\n    An abstract generic base class for repositories.\n    It uses `Self` in its abstract class method return type.\n    \"\"\"\n    @classmethod\n    @abstractmethod\n    def create_default(cls, value: T) -> Self:\n        \"\"\"\n        Creates a default instance of `Self`, parameterized by `T`.\n        `Self` should resolve to the concrete class with its specific `T` type argument.\n        \"\"\"\n        pass\n\nclass UserRepository(BaseRepository[str]):\n    \"\"\"\n    A concrete implementation of BaseRepository for strings.\n    `T` is fixed to `str` here.\n    \"\"\"\n    @classmethod\n    def create_default(cls, value: str) -> Self:\n        print(f\"Creating default UserRepository with value: {value}\")\n        # In a real impl, might initialize an instance using 'value'.\n        return cls()\n\ndef process_repository[R: BaseRepository[Any]](repo_type: type[R], initial_value: Any) -> R:\n    \"\"\"\n    Takes a repository *type* (e.g., UserRepository) and calls its class method.\n    The return type `R` relies on `Self` being correctly inferred with its\n    generic type parameters from the actual `repo_type`.\n    \"\"\"\n    return repo_type.create_default(initial_value)\n\nif __name__ == \"__main__\":\n    # DIVERGENCE POINT:\n    # Mypy correctly infers that `UserRepository.create_default` returns `UserRepository[str]`\n    # because `Self` resolves to the specific class `UserRepository` and preserves its `str` type argument.\n    # Therefore, the assignment to `processed_repo` as `UserRepository[str]` is valid.\n    # Other type checkers might struggle to preserve the `str` type parameter\n    # through `Self` when `create_default` is called via the generic function `process_repository`.\n    # They might infer `BaseRepository[Any]` or `BaseRepository[str]` for `processed_repo`,\n    # leading to an assignment error (as `BaseRepository[str]` is not `UserRepository[str]`).\n    processed_repo: UserRepository[str] = process_repository(UserRepository, \"default_user_name\")\n    print(f\"Created repository of type: {type(processed_repo)} for value: '{processed_repo}'\")\n\n    # Example of using the created instance (should be fine if type inference succeeded).\n    # If `processed_repo` lost its specific generic type, this might lead to further errors.\n    # reveal_type(processed_repo) # Should show UserRepository[str]",
            "full_content": "# id: self-generic-abstract-inference\n# category: self-generic\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n\nfrom typing import TypeVar, Generic, Self, Any\nfrom abc import ABC, abstractmethod\n\nT = TypeVar('T')\n\nclass BaseRepository(Generic[T], ABC):\n    \"\"\"\n    An abstract generic base class for repositories.\n    It uses `Self` in its abstract class method return type.\n    \"\"\"\n    @classmethod\n    @abstractmethod\n    def create_default(cls, value: T) -> Self:\n        \"\"\"\n        Creates a default instance of `Self`, parameterized by `T`.\n        `Self` should resolve to the concrete class with its specific `T` type argument.\n        \"\"\"\n        pass\n\nclass UserRepository(BaseRepository[str]):\n    \"\"\"\n    A concrete implementation of BaseRepository for strings.\n    `T` is fixed to `str` here.\n    \"\"\"\n    @classmethod\n    def create_default(cls, value: str) -> Self:\n        print(f\"Creating default UserRepository with value: {value}\")\n        # In a real impl, might initialize an instance using 'value'.\n        return cls()\n\ndef process_repository[R: BaseRepository[Any]](repo_type: type[R], initial_value: Any) -> R:\n    \"\"\"\n    Takes a repository *type* (e.g., UserRepository) and calls its class method.\n    The return type `R` relies on `Self` being correctly inferred with its\n    generic type parameters from the actual `repo_type`.\n    \"\"\"\n    return repo_type.create_default(initial_value)\n\nif __name__ == \"__main__\":\n    # DIVERGENCE POINT:\n    # Mypy correctly infers that `UserRepository.create_default` returns `UserRepository[str]`\n    # because `Self` resolves to the specific class `UserRepository` and preserves its `str` type argument.\n    # Therefore, the assignment to `processed_repo` as `UserRepository[str]` is valid.\n    # Other type checkers might struggle to preserve the `str` type parameter\n    # through `Self` when `create_default` is called via the generic function `process_repository`.\n    # They might infer `BaseRepository[Any]` or `BaseRepository[str]` for `processed_repo`,\n    # leading to an assignment error (as `BaseRepository[str]` is not `UserRepository[str]`).\n    processed_repo: UserRepository[str] = process_repository(UserRepository, \"default_user_name\")\n    print(f\"Created repository of type: {type(processed_repo)} for value: '{processed_repo}'\")\n\n    # Example of using the created instance (should be fine if type inference succeeded).\n    # If `processed_repo` lost its specific generic type, this might lead to further errors.\n    # reveal_type(processed_repo) # Should show UserRepository[str]"
        },
        {
            "id": "newtype-list-covariance",
            "metadata": "# category: newtype-containers\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error",
            "code": "from typing import NewType, List, Tuple\n\n# Define NewTypes based on built-in types.\nUserID = NewType('UserID', int)\nOrderID = NewType('OrderID', str)\n\n# A function expecting a list of the base type (int).\ndef process_int_list(data: List[int]) -> None:\n    print(f\"Processing integers: {data}\")\n\n# A function expecting a tuple of the base type (str).\ndef process_str_tuple(data: Tuple[str, ...]) -> None:\n    print(f\"Processing strings: {data}\")\n\nif __name__ == \"__main__\":\n    # Create instances of generic containers using NewTypes.\n    user_id_list: List[UserID] = [UserID(101), UserID(102)]\n    order_id_tuple: Tuple[OrderID, ...] = (OrderID(\"ORD_001\"), OrderID(\"ORD_002\"))\n\n    # DIVERGENCE POINT 1: List Covariance\n    # `List` is covariant in its type parameter. Therefore, `List[UserID]` should be\n    # assignable to `List[int]`, because `UserID` is a subtype of `int`.\n    # Mypy correctly handles this. Other type checkers might be stricter and\n    # flag an error, treating `NewType` as too distinct from its base type\n    # within generic contexts.\n    print(\"--- Testing List Covariance ---\")\n    process_int_list(user_id_list) # mypy: ok, others: error\n\n    # DIVERGENCE POINT 2: Tuple Covariance\n    # `Tuple` is also covariant. `Tuple[OrderID, ...]` should be assignable to\n    # `Tuple[str, ...]`. Similar to List, this tests the type checker's\n    # understanding of `NewType` and container variance.\n    print(\"\\n--- Testing Tuple Covariance ---\")\n    process_str_tuple(order_id_tuple) # mypy: ok, others: error",
            "full_content": "# id: newtype-list-covariance\n# category: newtype-containers\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n\nfrom typing import NewType, List, Tuple\n\n# Define NewTypes based on built-in types.\nUserID = NewType('UserID', int)\nOrderID = NewType('OrderID', str)\n\n# A function expecting a list of the base type (int).\ndef process_int_list(data: List[int]) -> None:\n    print(f\"Processing integers: {data}\")\n\n# A function expecting a tuple of the base type (str).\ndef process_str_tuple(data: Tuple[str, ...]) -> None:\n    print(f\"Processing strings: {data}\")\n\nif __name__ == \"__main__\":\n    # Create instances of generic containers using NewTypes.\n    user_id_list: List[UserID] = [UserID(101), UserID(102)]\n    order_id_tuple: Tuple[OrderID, ...] = (OrderID(\"ORD_001\"), OrderID(\"ORD_002\"))\n\n    # DIVERGENCE POINT 1: List Covariance\n    # `List` is covariant in its type parameter. Therefore, `List[UserID]` should be\n    # assignable to `List[int]`, because `UserID` is a subtype of `int`.\n    # Mypy correctly handles this. Other type checkers might be stricter and\n    # flag an error, treating `NewType` as too distinct from its base type\n    # within generic contexts.\n    print(\"--- Testing List Covariance ---\")\n    process_int_list(user_id_list) # mypy: ok, others: error\n\n    # DIVERGENCE POINT 2: Tuple Covariance\n    # `Tuple` is also covariant. `Tuple[OrderID, ...]` should be assignable to\n    # `Tuple[str, ...]`. Similar to List, this tests the type checker's\n    # understanding of `NewType` and container variance.\n    print(\"\\n--- Testing Tuple Covariance ---\")\n    process_str_tuple(order_id_tuple) # mypy: ok, others: error"
        },
        {
            "id": "overload-literal-resolution",
            "metadata": "# category: overload-literals\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error",
            "code": "from typing import overload, Literal, Union\n\n# Overload 1: Most specific for \"apple\"\n@overload\ndef get_fruit_info(fruit: Literal[\"apple\"]) -> dict[str, str]: ...\n# Overload 2: Less specific, includes \"apple\" and \"orange\". This overlaps with Overload 1.\n@overload\ndef get_fruit_info(fruit: Literal[\"apple\", \"orange\"]) -> dict[str, int]: ...\n# Overload 3: General string, least specific.\n@overload\ndef get_fruit_info(fruit: str) -> dict[str, bool]: ...\n\ndef get_fruit_info(fruit: str) -> Union[dict[str, str], dict[str, int], dict[str, bool]]:\n    \"\"\"Implementation for get_fruit_info.\"\"\"\n    if fruit == \"apple\":\n        return {\"color\": \"red\"}\n    elif fruit == \"orange\":\n        return {\"segments\": 10}\n    else:\n        return {\"available\": False}\n\nif __name__ == \"__main__\":\n    # DIVERGENCE POINT: Calling with \"apple\"\n    # Overload resolution order is critical here. Mypy's rule is to pick the\n    # *first* matching overload in the source order.\n    # Therefore, `get_fruit_info(\"apple\")` should resolve to Overload 1,\n    # resulting in `apple_info` being `dict[str, str]`.\n    # Other type checkers might use different heuristics (e.g., longest literal list wins),\n    # leading to `apple_info` being `dict[str, int]` (from Overload 2), or a `Union`.\n    apple_info = get_fruit_info(\"apple\")\n    \n    # If `apple_info` is inferred as `dict[str, int]`, then accessing \"color\"\n    # or assigning its value to `str` will be an error, as `dict[str, int]`\n    # does not guarantee a \"color\" key with a string value.\n    apple_color: str = apple_info[\"color\"] # This assignment is the divergence test.\n    print(f\"Apple info color: {apple_color}\")\n\n    # This should unambiguously resolve to Overload 2 for all checkers.\n    orange_info = get_fruit_info(\"orange\")\n    orange_segments: int = orange_info[\"segments\"]\n    print(f\"Orange info segments: {orange_segments}\")\n\n    # This should unambiguously resolve to Overload 3 for all checkers.\n    banana_info = get_fruit_info(\"banana\")\n    banana_available: bool = banana_info[\"available\"]\n    print(f\"Banana info available: {banana_available}\")",
            "full_content": "# id: overload-literal-resolution\n# category: overload-literals\n# expected: mypy: ok, pyrefly: error, zuban: error, ty: error\n\nfrom typing import overload, Literal, Union\n\n# Overload 1: Most specific for \"apple\"\n@overload\ndef get_fruit_info(fruit: Literal[\"apple\"]) -> dict[str, str]: ...\n# Overload 2: Less specific, includes \"apple\" and \"orange\". This overlaps with Overload 1.\n@overload\ndef get_fruit_info(fruit: Literal[\"apple\", \"orange\"]) -> dict[str, int]: ...\n# Overload 3: General string, least specific.\n@overload\ndef get_fruit_info(fruit: str) -> dict[str, bool]: ...\n\ndef get_fruit_info(fruit: str) -> Union[dict[str, str], dict[str, int], dict[str, bool]]:\n    \"\"\"Implementation for get_fruit_info.\"\"\"\n    if fruit == \"apple\":\n        return {\"color\": \"red\"}\n    elif fruit == \"orange\":\n        return {\"segments\": 10}\n    else:\n        return {\"available\": False}\n\nif __name__ == \"__main__\":\n    # DIVERGENCE POINT: Calling with \"apple\"\n    # Overload resolution order is critical here. Mypy's rule is to pick the\n    # *first* matching overload in the source order.\n    # Therefore, `get_fruit_info(\"apple\")` should resolve to Overload 1,\n    # resulting in `apple_info` being `dict[str, str]`.\n    # Other type checkers might use different heuristics (e.g., longest literal list wins),\n    # leading to `apple_info` being `dict[str, int]` (from Overload 2), or a `Union`.\n    apple_info = get_fruit_info(\"apple\")\n    \n    # If `apple_info` is inferred as `dict[str, int]`, then accessing \"color\"\n    # or assigning its value to `str` will be an error, as `dict[str, int]`\n    # does not guarantee a \"color\" key with a string value.\n    apple_color: str = apple_info[\"color\"] # This assignment is the divergence test.\n    print(f\"Apple info color: {apple_color}\")\n\n    # This should unambiguously resolve to Overload 2 for all checkers.\n    orange_info = get_fruit_info(\"orange\")\n    orange_segments: int = orange_info[\"segments\"]\n    print(f\"Orange info segments: {orange_segments}\")\n\n    # This should unambiguously resolve to Overload 3 for all checkers.\n    banana_info = get_fruit_info(\"banana\")\n    banana_available: bool = banana_info[\"available\"]\n    print(f\"Banana info available: {banana_available}\")"
        },
        {
            "id": "final-attribute-property-override",
            "metadata": "# category: final-override\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok",
            "code": "from typing import Final\n\nclass Configuration:\n    \"\"\"A base class with Final class attributes.\"\"\"\n    SETTING_A: Final[str] = \"default_value_A\"\n    SETTING_B: Final[int] = 100\n\nclass CustomConfiguration(Configuration):\n    \"\"\"\n    A subclass attempting to override Final attributes.\n    \"\"\"\n    # DIVERGENCE POINT:\n    # Overriding a Final class attribute (`SETTING_A`) with a property.\n    # PEP 591 states: \"In a class body, Final variables cannot be overridden in subclasses.\"\n    # Mypy interprets a property as an override of the Final attribute and flags an error.\n    # Other type checkers might consider a property a distinct kind of class member\n    # (a descriptor, not a simple variable assignment) and allow this override,\n    # or they might not implement this specific check for `Final` in this scenario.\n    @property\n    def SETTING_A(self) -> str:\n        return \"custom_value_for_A\"\n\n    # This is a direct override of a Final attribute with a different type,\n    # which should typically be an error for all compliant type checkers.\n    # SETTING_B: Final[str] = \"200\" # Uncomment to test a universally expected error.\n\nif __name__ == \"__main__\":\n    # Accessing the original Final attributes.\n    print(f\"Base SETTING_A: {Configuration.SETTING_A}\")\n    print(f\"Base SETTING_B: {Configuration.SETTING_B}\")\n\n    # Accessing the potentially overridden attributes in CustomConfiguration.\n    # If the checker permits the property override (i.e., not mypy),\n    # this will print the value from the property.\n    custom_config = CustomConfiguration()\n    print(f\"Custom SETTING_A (via property): {custom_config.SETTING_A}\")\n    # MyPy would have already flagged an error at the class definition of CustomConfiguration.",
            "full_content": "# id: final-attribute-property-override\n# category: final-override\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n\nfrom typing import Final\n\nclass Configuration:\n    \"\"\"A base class with Final class attributes.\"\"\"\n    SETTING_A: Final[str] = \"default_value_A\"\n    SETTING_B: Final[int] = 100\n\nclass CustomConfiguration(Configuration):\n    \"\"\"\n    A subclass attempting to override Final attributes.\n    \"\"\"\n    # DIVERGENCE POINT:\n    # Overriding a Final class attribute (`SETTING_A`) with a property.\n    # PEP 591 states: \"In a class body, Final variables cannot be overridden in subclasses.\"\n    # Mypy interprets a property as an override of the Final attribute and flags an error.\n    # Other type checkers might consider a property a distinct kind of class member\n    # (a descriptor, not a simple variable assignment) and allow this override,\n    # or they might not implement this specific check for `Final` in this scenario.\n    @property\n    def SETTING_A(self) -> str:\n        return \"custom_value_for_A\"\n\n    # This is a direct override of a Final attribute with a different type,\n    # which should typically be an error for all compliant type checkers.\n    # SETTING_B: Final[str] = \"200\" # Uncomment to test a universally expected error.\n\nif __name__ == \"__main__\":\n    # Accessing the original Final attributes.\n    print(f\"Base SETTING_A: {Configuration.SETTING_A}\")\n    print(f\"Base SETTING_B: {Configuration.SETTING_B}\")\n\n    # Accessing the potentially overridden attributes in CustomConfiguration.\n    # If the checker permits the property override (i.e., not mypy),\n    # this will print the value from the property.\n    custom_config = CustomConfiguration()\n    print(f\"Custom SETTING_A (via property): {custom_config.SETTING_A}\")\n    # MyPy would have already flagged an error at the class definition of CustomConfiguration."
        },
        {
            "id": "keyword-vs-positional-protocol",
            "metadata": "# category: keyword-vs-positional\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok",
            "code": "from typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass HasProcessor(Protocol):\n    \"\"\"\n    Protocol method with a positional-or-keyword argument ('value')\n    and a keyword-only argument ('factor').\n    \"\"\"\n    def process(self, value: int, *, factor: float = 1.0) -> float: ...\n\nclass StrictProcessor:\n    \"\"\"\n    Implements the protocol by making 'value' keyword-only.\n    This changes 'value' from positional-or-keyword to keyword-only.\n    \"\"\"\n    def process(self, *, value: int, factor: float = 1.0) -> float:\n        return value * factor\n\nclass LooseProcessor:\n    \"\"\"\n    Implements the protocol by making 'factor' positional-or-keyword.\n    This makes the method *more flexible*, which is generally allowed by PEP 544.\n    \"\"\"\n    def process(self, value: int, factor: float = 1.0) -> float:\n        return value * factor\n\ndef operate(obj: HasProcessor) -> None:\n    \"\"\"\n    Function that calls the `process` method, adhering to the protocol's signature.\n    \"\"\"\n    print(f\"Processing object: {type(obj).__name__}\")\n    # These calls are valid for the `HasProcessor` protocol.\n    # They should only be statically allowed if `obj` truly implements `HasProcessor`.\n    print(f\"  Result (pos-arg, kw-arg): {obj.process(10, factor=2.0)}\")\n    print(f\"  Result (kw-arg, kw-arg): {obj.process(value=20, factor=3.0)}\")\n    print(f\"  Result (pos-arg, default): {obj.process(30)}\")\n\nif __name__ == \"__main__\":\n    lp = LooseProcessor()\n    print(\"--- Testing LooseProcessor (should be OK for all) ---\")\n    operate(lp) # This should pass for all checkers and at runtime.\n\n    sp = StrictProcessor()\n    print(\"\\n--- Testing StrictProcessor (Divergence) ---\")\n    # DIVERGENCE POINT:\n    # Mypy considers `StrictProcessor` NOT to implement `HasProcessor` because\n    # the parameter `value` changed from `positional-or-keyword` in the protocol\n    # to `keyword-only` in the implementation. This makes the implementation\n    # *less flexible* than the protocol, which PEP 544 disallows.\n    # Other type checkers might allow this, or be more lenient on parameter kinds.\n    operate(sp) # mypy: error (at the `operate(sp)` call site), others: ok.",
            "full_content": "# id: keyword-vs-positional-protocol\n# category: keyword-vs-positional\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n\nfrom typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass HasProcessor(Protocol):\n    \"\"\"\n    Protocol method with a positional-or-keyword argument ('value')\n    and a keyword-only argument ('factor').\n    \"\"\"\n    def process(self, value: int, *, factor: float = 1.0) -> float: ...\n\nclass StrictProcessor:\n    \"\"\"\n    Implements the protocol by making 'value' keyword-only.\n    This changes 'value' from positional-or-keyword to keyword-only.\n    \"\"\"\n    def process(self, *, value: int, factor: float = 1.0) -> float:\n        return value * factor\n\nclass LooseProcessor:\n    \"\"\"\n    Implements the protocol by making 'factor' positional-or-keyword.\n    This makes the method *more flexible*, which is generally allowed by PEP 544.\n    \"\"\"\n    def process(self, value: int, factor: float = 1.0) -> float:\n        return value * factor\n\ndef operate(obj: HasProcessor) -> None:\n    \"\"\"\n    Function that calls the `process` method, adhering to the protocol's signature.\n    \"\"\"\n    print(f\"Processing object: {type(obj).__name__}\")\n    # These calls are valid for the `HasProcessor` protocol.\n    # They should only be statically allowed if `obj` truly implements `HasProcessor`.\n    print(f\"  Result (pos-arg, kw-arg): {obj.process(10, factor=2.0)}\")\n    print(f\"  Result (kw-arg, kw-arg): {obj.process(value=20, factor=3.0)}\")\n    print(f\"  Result (pos-arg, default): {obj.process(30)}\")\n\nif __name__ == \"__main__\":\n    lp = LooseProcessor()\n    print(\"--- Testing LooseProcessor (should be OK for all) ---\")\n    operate(lp) # This should pass for all checkers and at runtime.\n\n    sp = StrictProcessor()\n    print(\"\\n--- Testing StrictProcessor (Divergence) ---\")\n    # DIVERGENCE POINT:\n    # Mypy considers `StrictProcessor` NOT to implement `HasProcessor` because\n    # the parameter `value` changed from `positional-or-keyword` in the protocol\n    # to `keyword-only` in the implementation. This makes the implementation\n    # *less flexible* than the protocol, which PEP 544 disallows.\n    # Other type checkers might allow this, or be more lenient on parameter kinds.\n    operate(sp) # mypy: error (at the `operate(sp)` call site), others: ok."
        },
        {
            "id": "bounded-typevar-nested-protocol",
            "metadata": "# category: bounded-typevars\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok",
            "code": "from typing import TypeVar, Generic, Iterable, Protocol, runtime_checkable\n\n# Define a protocol for types that must have a 'get_name' method returning a string.\n@runtime_checkable\nclass NamedThing(Protocol):\n    def get_name(self) -> str: ...\n\n# A TypeVar whose bound is `Iterable[NamedThing]`.\n# This means any type substituted for `T_NamedIterable` must be an iterable\n# where *each element* satisfies the `NamedThing` protocol.\nT_NamedIterable = TypeVar('T_NamedIterable', bound=Iterable[NamedThing])\n\n# A generic function that takes an iterable of `NamedThing`s and prints their names.\ndef print_names[I: T_NamedIterable](data: I) -> None:\n    for item in data:\n        print(f\"Name: {item.get_name()}\")\n\n# A class that explicitly implements the NamedThing protocol.\nclass MyObject:\n    def __init__(self, name: str):\n        self._name = name\n    def get_name(self) -> str:\n        return self._name\n\n# A class that does NOT implement the NamedThing protocol (it lacks `get_name`).\nclass MyOtherObject:\n    def __init__(self, value: int):\n        self._value = value\n\nif __name__ == \"__main__\":\n    # Case 1: List of objects that implement NamedThing. This should pass for all.\n    named_objects: list[MyObject] = [MyObject(\"Alpha\"), MyObject(\"Beta\")]\n    print(\"\\n--- Printing names of MyObject instances ---\")\n    print_names(named_objects)\n\n    # DIVERGENCE POINT:\n    # Passing a list of objects that do NOT implement `NamedThing`.\n    # `MyOtherObject` does not have a `get_name` method.\n    # Therefore, `list[MyOtherObject]` should NOT be compatible with\n    # `Iterable[NamedThing]` according to the `T_NamedIterable` TypeVar bound.\n    # Mypy correctly identifies this as a type error because `MyOtherObject` does not\n    # satisfy the `NamedThing` protocol.\n    # Other type checkers might be more lenient, or simply fail to perform this complex\n    # nested generic bound check, allowing the code to pass statically but leading\n    # to a runtime `AttributeError`.\n    other_objects: list[MyOtherObject] = [MyOtherObject(1), MyOtherObject(2)]\n    print(\"\\n--- Printing names of MyOtherObject instances (EXPECTED ERROR) ---\")\n    print_names(other_objects) # mypy: error, others: ok.\n\n    # An empty list satisfies the bound for any `Iterable[T]`.\n    empty_list: list[NamedThing] = []\n    print(\"\\n--- Printing names of empty list ---\")\n    print_names(empty_list)",
            "full_content": "# id: bounded-typevar-nested-protocol\n# category: bounded-typevars\n# expected: mypy: error, pyrefly: ok, zuban: ok, ty: ok\n\nfrom typing import TypeVar, Generic, Iterable, Protocol, runtime_checkable\n\n# Define a protocol for types that must have a 'get_name' method returning a string.\n@runtime_checkable\nclass NamedThing(Protocol):\n    def get_name(self) -> str: ...\n\n# A TypeVar whose bound is `Iterable[NamedThing]`.\n# This means any type substituted for `T_NamedIterable` must be an iterable\n# where *each element* satisfies the `NamedThing` protocol.\nT_NamedIterable = TypeVar('T_NamedIterable', bound=Iterable[NamedThing])\n\n# A generic function that takes an iterable of `NamedThing`s and prints their names.\ndef print_names[I: T_NamedIterable](data: I) -> None:\n    for item in data:\n        print(f\"Name: {item.get_name()}\")\n\n# A class that explicitly implements the NamedThing protocol.\nclass MyObject:\n    def __init__(self, name: str):\n        self._name = name\n    def get_name(self) -> str:\n        return self._name\n\n# A class that does NOT implement the NamedThing protocol (it lacks `get_name`).\nclass MyOtherObject:\n    def __init__(self, value: int):\n        self._value = value\n\nif __name__ == \"__main__\":\n    # Case 1: List of objects that implement NamedThing. This should pass for all.\n    named_objects: list[MyObject] = [MyObject(\"Alpha\"), MyObject(\"Beta\")]\n    print(\"\\n--- Printing names of MyObject instances ---\")\n    print_names(named_objects)\n\n    # DIVERGENCE POINT:\n    # Passing a list of objects that do NOT implement `NamedThing`.\n    # `MyOtherObject` does not have a `get_name` method.\n    # Therefore, `list[MyOtherObject]` should NOT be compatible with\n    # `Iterable[NamedThing]` according to the `T_NamedIterable` TypeVar bound.\n    # Mypy correctly identifies this as a type error because `MyOtherObject` does not\n    # satisfy the `NamedThing` protocol.\n    # Other type checkers might be more lenient, or simply fail to perform this complex\n    # nested generic bound check, allowing the code to pass statically but leading\n    # to a runtime `AttributeError`.\n    other_objects: list[MyOtherObject] = [MyOtherObject(1), MyOtherObject(2)]\n    print(\"\\n--- Printing names of MyOtherObject instances (EXPECTED ERROR) ---\")\n    print_names(other_objects) # mypy: error, others: ok.\n\n    # An empty list satisfies the bound for any `Iterable[T]`.\n    empty_list: list[NamedThing] = []\n    print(\"\\n--- Printing names of empty list ---\")\n    print_names(empty_list)"
        }
    ]
}